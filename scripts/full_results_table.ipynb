{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1048a52-5c82-4045-99e3-2de9c2d14204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/InstaDeep/debatellm/\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2023 InstaDeep Ltd. All rights reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import os\n",
    "\n",
    "import neptune\n",
    "from tabulate import tabulate\n",
    "\n",
    "from visualise_utils import (get_unique_description)\n",
    "import pandas as pd\n",
    "\n",
    "# Set the chart type and dataset to plot\n",
    "chart_type = \"config_table\" \n",
    "\n",
    "dataset_dfs = {}\n",
    "datasets = [\"medqa\", \"mmlu\", \"pubmedqa\", \"cosmosqa\", \"ciar\", \"gpqa\"]\n",
    "run_range = [2244, 2538] #[2244, 2410]  # All: [2244, 2410]  # Faithful runs: [2244, 2323]\n",
    "sparse_legend = True\n",
    "\n",
    "# Initialize Neptune\n",
    "API_TOKEN = os.environ[\"TM_NEPTUNE_API_TOKEN\"]\n",
    "project = neptune.init_project(\n",
    "    project=\"InstaDeep/debatellm\",\n",
    "    mode=\"read-only\",\n",
    ")\n",
    "\n",
    "# ADD TRUEM- to the beginning of the run ids\n",
    "full_run_ids = [f\"TRUEM-{run_id}\" for run_id in range(run_range[0], run_range[1] + 1)]\n",
    "runs_table_df = project.fetch_runs_table(id=full_run_ids).to_pandas()\n",
    "\n",
    "# Set the index based on the custom names\n",
    "runs_table_df = runs_table_df.set_index(\"sys/id\")\n",
    "\n",
    "# Filter out all runs not initiated by k.tessara\n",
    "runs_table_df = runs_table_df[runs_table_df[\"sys/owner\"].isin([\"k.tessera\", \"ap.smit\"])]\n",
    "\n",
    "# Filter out all runs that where less than 80% completed\n",
    "runs_table_df = runs_table_df[runs_table_df[\"eval/percent_complete\"] >= 100.0]\n",
    "\n",
    "# Filter out all runs that are not from the current dataset\n",
    "runs_table_df = runs_table_df[runs_table_df[\"config/dataset/eval_dataset\"].isin(datasets)]\n",
    "\n",
    "# Discard all keys with monitoring in their name.\n",
    "runs_table_df = runs_table_df[\n",
    "    [key for key in runs_table_df.keys() if \"eval/\" in key or \"config/\" in key]\n",
    "]\n",
    "# dataset_dfs[dataset] = runs_table_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3c5934d-8a6c-494e-b590-2795a53ad7e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVED:  TRUEM-2475\n",
      "REMOVED:  TRUEM-2474\n",
      "REMOVED:  TRUEM-2384\n"
     ]
    }
   ],
   "source": [
    "pd.set_option(\"display.precision\", 2)\n",
    "\n",
    "results = {\"mmlu\" : [], \"pubmedqa\" : [], \"medqa\" : []}\n",
    "for unique_id in runs_table_df.index:\n",
    "    \n",
    "    score = runs_table_df[\"eval/score/total_acc\"][unique_id]\n",
    "    cost = runs_table_df[\"eval/total_cost\"][unique_id]\n",
    "    dataset = runs_table_df[\"config/dataset/eval_dataset\"][unique_id]\n",
    "    id = unique_id\n",
    "\n",
    "    description = get_unique_description(\n",
    "        runs_table_df, unique_id, include_prompts=True\n",
    "    )\n",
    "\n",
    "    examples = runs_table_df[\"config/system/use_few_shot_examples\"][unique_id]\n",
    "    incorrectly_parsed_Agent_0 = runs_table_df[\"eval/Agent_0/any_incorrectly_parsed_answer\"][unique_id]\n",
    "    \n",
    "    # Round score and cost\n",
    "    score = round(score, 2)\n",
    "    cost = round(cost, 2)\n",
    "    system_name, description = description.split(\" - \", 1)\n",
    "    if \"single_agent\" in description: \n",
    "        system_name = \"Single Agent\"\n",
    "\n",
    "    if \"1:1\" in description:\n",
    "        print(\"REMOVED: \", unique_id)\n",
    "        continue\n",
    "\n",
    "    #Remove the Improved Multi-Persona Experiments\n",
    "    if 'TRUEM-2359' in unique_id:\n",
    "        continue\n",
    "\n",
    "    description, agent_prompt = description.split(\", agent prompt: \", 1)\n",
    "    description, debate_prompt = description.split(\", debate prompt: \", 1)\n",
    "\n",
    "    if not pd.isna(examples) and examples: \n",
    "        agent_prompt = agent_prompt +\" + FS\"\n",
    "\n",
    "    if system_name == \"Single Agent\":\n",
    "        debate_prompt = \"-\"\n",
    "\n",
    "    if \"PaLM\" in description:\n",
    "        agent = \"PaLM\"\n",
    "    else:\n",
    "        agent = \"GPT3.5\"\n",
    "\n",
    "    results[dataset].append((system_name, debate_prompt, agent_prompt, description, agent, unique_id, score, cost, incorrectly_parsed_Agent_0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e336e73-7969-45d3-9c14-3776b0753bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mmlu', 71), ('pubmedqa', 52), ('medqa', 55)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(key, len(results[key])) for key in results.keys()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f4859b4-eb1d-4068-8cb1-4f493d33303d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset =  medqa Original shape =  (55, 9) Shape after merging =  (50, 9)\n",
      "Dataset =  mmlu Original shape =  (71, 9) Shape after merging =  (50, 9)\n",
      "Dataset =  pubmedqa Original shape =  (52, 9) Shape after merging =  (50, 9)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'cosmosqa'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m      3\u001b[0m     column_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSystem Name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDebate Prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgent Prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgents\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeptuneID\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScore (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39mdataset\u001b[38;5;241m.\u001b[39mupper(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCost \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m$ (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39mdataset\u001b[38;5;241m.\u001b[39mupper(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgent0: Incorrectly Parsed\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m]\u001b[49m, columns \u001b[38;5;241m=\u001b[39m column_names)\u001b[38;5;241m.\u001b[39msort_values([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSystem Name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDebate Prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgent Prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgents\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScore (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39mdataset\u001b[38;5;241m.\u001b[39mupper()])\n\u001b[1;32m      6\u001b[0m     df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m dataset\u001b[38;5;241m.\u001b[39mupper()] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeptuneID\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      7\u001b[0m     df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIP (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m dataset\u001b[38;5;241m.\u001b[39mupper()] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgent0: Incorrectly Parsed\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cosmosqa'"
     ]
    }
   ],
   "source": [
    "results_df = {}\n",
    "for dataset in datasets:\n",
    "    column_names = [\"System Name\", \"Debate Prompt\", \"Agent Prompt\", \"Config\", \"Agents\", \"NeptuneID\", \"Score (%s)\" %dataset.upper(), \"Cost \\$ (%s)\" %dataset.upper(), \"Agent0: Incorrectly Parsed\"]\n",
    "    \n",
    "    df = pd.DataFrame(results[dataset], columns = column_names).sort_values([\"System Name\", \"Debate Prompt\", \"Agent Prompt\", \"Agents\", \"Score (%s)\" %dataset.upper()])\n",
    "    df[\"ID (%s)\" % dataset.upper()] = df[\"NeptuneID\"]\n",
    "    df[\"IP (%s)\" % dataset.upper()] = df[\"Agent0: Incorrectly Parsed\"]\n",
    "    \n",
    "    df.drop(columns=[\"NeptuneID\", \"Agent0: Incorrectly Parsed\"],inplace=True)\n",
    "    results_df[dataset] = df.drop_duplicates(subset=[\"System Name\", \"Debate Prompt\", \"Agent Prompt\", \"Config\", \"Agents\"], keep='last') # sorted in increasing score order, so this is the largest score\n",
    "    print(\"Dataset = \", dataset, \"Original shape = \", df.shape, \"Shape after merging = \", results_df[dataset].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf5dfa9-e41d-4ee6-b23c-8879da484899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df = {}\n",
    "# for dataset in datasets:\n",
    "#     column_names = [\"System Name\", \"Debate Prompt\", \"Agent Prompt\", \"Config\", \"Agents\", \"NeptuneID\", \"Score (%s)\" %dataset.upper(), \"Cost \\$ (%s)\" %dataset.upper()]\n",
    "    \n",
    "#     df = pd.DataFrame(results[dataset], columns = column_names).sort_values([\"System Name\", \"Debate Prompt\", \"Agent Prompt\", \"Agents\", \"Score (%s)\" %dataset.upper()])\n",
    "#     df[\"ID (%s)\" % dataset.upper()] = df[\"NeptuneID\"]\n",
    "#     df.drop(columns=[\"NeptuneID\"],inplace=True)\n",
    "#     results_df[dataset] = df.drop_duplicates(subset=[\"System Name\", \"Debate Prompt\", \"Agent Prompt\", \"Config\", \"Agents\"], keep='last') # sorted in increasing score order, so this is the largest score\n",
    "#     print(\"Dataset = \", dataset, \"Original shape = \", df.shape, \"Shape after merging = \", results_df[dataset].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d08aa9-f86f-4cad-9172-b29e50a19a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 13)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.merge(results_df[\"medqa\"], results_df[\"pubmedqa\"], how=\"outer\", on=[\"System Name\", \"Debate Prompt\", \"Agent Prompt\", \"Config\", \"Agents\"])\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bb52a1-47d3-464d-a5e8-41c0294cfb91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50, 13), (50, 9), (50, 17))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = pd.merge(temp, results_df[\"mmlu\"], how=\"outer\", on=[\"System Name\", \"Debate Prompt\", \"Agent Prompt\", \"Config\", \"Agents\"]).sort_values([\"System Name\", \"Debate Prompt\"])\n",
    "temp.shape, results_df[\"mmlu\"].shape, merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f370c032-65bf-4c1d-b86f-8e7d68253e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System Name</th>\n",
       "      <th>Debate Prompt</th>\n",
       "      <th>Agent Prompt</th>\n",
       "      <th>Config</th>\n",
       "      <th>Agents</th>\n",
       "      <th>Score (MEDQA)</th>\n",
       "      <th>Cost \\$ (MEDQA)</th>\n",
       "      <th>ID (MEDQA)</th>\n",
       "      <th>IP (MEDQA)</th>\n",
       "      <th>Score (PUBMEDQA)</th>\n",
       "      <th>Cost \\$ (PUBMEDQA)</th>\n",
       "      <th>ID (PUBMEDQA)</th>\n",
       "      <th>IP (PUBMEDQA)</th>\n",
       "      <th>Score (MMLU)</th>\n",
       "      <th>Cost \\$ (MMLU)</th>\n",
       "      <th>ID (MMLU)</th>\n",
       "      <th>IP (MMLU)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Multi-Persona</td>\n",
       "      <td>tsinghua_ma_debate</td>\n",
       "      <td>angel</td>\n",
       "      <td>2 rounds max</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.49</td>\n",
       "      <td>14.27</td>\n",
       "      <td>TRUEM-2320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.57</td>\n",
       "      <td>7.15</td>\n",
       "      <td>TRUEM-2402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.33</td>\n",
       "      <td>TRUEM-2489</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Multi-Persona</td>\n",
       "      <td>tsinghua_ma_debate</td>\n",
       "      <td>angel</td>\n",
       "      <td>4 rounds max</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>14.70</td>\n",
       "      <td>TRUEM-2319</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.60</td>\n",
       "      <td>9.52</td>\n",
       "      <td>TRUEM-2404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.33</td>\n",
       "      <td>TRUEM-2491</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Multi-Persona</td>\n",
       "      <td>tsinghua_ma_debate</td>\n",
       "      <td>angel</td>\n",
       "      <td>3 rounds max</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.51</td>\n",
       "      <td>14.60</td>\n",
       "      <td>TRUEM-2318</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.59</td>\n",
       "      <td>8.49</td>\n",
       "      <td>TRUEM-2403</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.34</td>\n",
       "      <td>TRUEM-2490</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      System Name       Debate Prompt Agent Prompt        Config  Agents  \\\n",
       "22  Multi-Persona  tsinghua_ma_debate        angel  2 rounds max  GPT3.5   \n",
       "23  Multi-Persona  tsinghua_ma_debate        angel  4 rounds max  GPT3.5   \n",
       "24  Multi-Persona  tsinghua_ma_debate        angel  3 rounds max  GPT3.5   \n",
       "\n",
       "    Score (MEDQA)  Cost \\$ (MEDQA)  ID (MEDQA)  IP (MEDQA)  Score (PUBMEDQA)  \\\n",
       "22           0.49            14.27  TRUEM-2320         NaN              0.57   \n",
       "23           0.50            14.70  TRUEM-2319         NaN              0.60   \n",
       "24           0.51            14.60  TRUEM-2318         NaN              0.59   \n",
       "\n",
       "    Cost \\$ (PUBMEDQA) ID (PUBMEDQA)  IP (PUBMEDQA)  Score (MMLU)  \\\n",
       "22                7.15    TRUEM-2402            NaN          0.63   \n",
       "23                9.52    TRUEM-2404            NaN          0.67   \n",
       "24                8.49    TRUEM-2403            NaN          0.63   \n",
       "\n",
       "    Cost \\$ (MMLU)   ID (MMLU)  IP (MMLU)  \n",
       "22            0.33  TRUEM-2489        NaN  \n",
       "23            0.33  TRUEM-2491        NaN  \n",
       "24            0.34  TRUEM-2490        NaN  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged[merged[\"System Name\"] == \"Multi-Persona\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e25c142-1b7e-4932-bff5-cdec17b72540",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv(\"ip_file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e7e39f-f7cf-4f1f-b70a-15eee3d6650d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System Name</th>\n",
       "      <th>Debate Prompt</th>\n",
       "      <th>Agent Prompt</th>\n",
       "      <th>Config</th>\n",
       "      <th>Agents</th>\n",
       "      <th>Score (MEDQA)</th>\n",
       "      <th>Cost \\$ (MEDQA)</th>\n",
       "      <th>ID (MEDQA)</th>\n",
       "      <th>Score (MMLU)</th>\n",
       "      <th>Cost \\$ (MMLU)</th>\n",
       "      <th>ID (MMLU)</th>\n",
       "      <th>Score (PUBMEDQA)</th>\n",
       "      <th>Cost \\$ (PUBMEDQA)</th>\n",
       "      <th>ID (PUBMEDQA)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ChatEval</td>\n",
       "      <td>chateval_ma_debate</td>\n",
       "      <td>cot</td>\n",
       "      <td>3 rounds, one_by_one</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.53</td>\n",
       "      <td>34.81</td>\n",
       "      <td>TRUEM-2441</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.73</td>\n",
       "      <td>TRUEM-2493</td>\n",
       "      <td>0.76</td>\n",
       "      <td>12.60</td>\n",
       "      <td>TRUEM-2406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ChatEval</td>\n",
       "      <td>chateval_ma_debate</td>\n",
       "      <td>cot</td>\n",
       "      <td>2 rounds, simultaneous_talk</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.54</td>\n",
       "      <td>19.90</td>\n",
       "      <td>TRUEM-2302</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.43</td>\n",
       "      <td>TRUEM-2494</td>\n",
       "      <td>0.74</td>\n",
       "      <td>7.27</td>\n",
       "      <td>TRUEM-2407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ChatEval</td>\n",
       "      <td>chateval_ma_debate</td>\n",
       "      <td>cot</td>\n",
       "      <td>3 rounds, simultaneous_talk_with_summarizer</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.55</td>\n",
       "      <td>36.78</td>\n",
       "      <td>TRUEM-2429</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.84</td>\n",
       "      <td>TRUEM-2497</td>\n",
       "      <td>0.77</td>\n",
       "      <td>14.01</td>\n",
       "      <td>TRUEM-2410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ChatEval</td>\n",
       "      <td>chateval_ma_debate</td>\n",
       "      <td>cot</td>\n",
       "      <td>2 rounds, one_by_one</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.55</td>\n",
       "      <td>20.55</td>\n",
       "      <td>TRUEM-2414</td>\n",
       "      <td>0.69</td>\n",
       "      <td>16.28</td>\n",
       "      <td>TRUEM-2362</td>\n",
       "      <td>0.76</td>\n",
       "      <td>7.64</td>\n",
       "      <td>TRUEM-2405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ChatEval</td>\n",
       "      <td>chateval_ma_debate</td>\n",
       "      <td>cot</td>\n",
       "      <td>2 rounds, simultaneous_talk_with_summarizer</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.55</td>\n",
       "      <td>22.58</td>\n",
       "      <td>TRUEM-2304</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.53</td>\n",
       "      <td>TRUEM-2496</td>\n",
       "      <td>0.72</td>\n",
       "      <td>8.76</td>\n",
       "      <td>TRUEM-2409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ChatEval</td>\n",
       "      <td>chateval_ma_debate</td>\n",
       "      <td>cot</td>\n",
       "      <td>3 rounds, simultaneous_talk</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.57</td>\n",
       "      <td>33.26</td>\n",
       "      <td>TRUEM-2303</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.72</td>\n",
       "      <td>TRUEM-2495</td>\n",
       "      <td>0.77</td>\n",
       "      <td>12.14</td>\n",
       "      <td>TRUEM-2408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ensemble Refinement</td>\n",
       "      <td>er_debate</td>\n",
       "      <td>er_few_shot</td>\n",
       "      <td>3:9 - ER, GPT</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.53</td>\n",
       "      <td>53.57</td>\n",
       "      <td>TRUEM-2271</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.26</td>\n",
       "      <td>TRUEM-2469</td>\n",
       "      <td>0.72</td>\n",
       "      <td>21.00</td>\n",
       "      <td>TRUEM-2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ensemble Refinement</td>\n",
       "      <td>er_debate</td>\n",
       "      <td>er_few_shot</td>\n",
       "      <td>3:1 - ER, GPT</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.53</td>\n",
       "      <td>17.83</td>\n",
       "      <td>TRUEM-2269</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.42</td>\n",
       "      <td>TRUEM-2467</td>\n",
       "      <td>0.72</td>\n",
       "      <td>7.00</td>\n",
       "      <td>TRUEM-2437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ensemble Refinement</td>\n",
       "      <td>er_debate</td>\n",
       "      <td>er_few_shot</td>\n",
       "      <td>5:0 - self_consistency, GPT</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.53</td>\n",
       "      <td>22.28</td>\n",
       "      <td>TRUEM-2261</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.53</td>\n",
       "      <td>TRUEM-2459</td>\n",
       "      <td>0.70</td>\n",
       "      <td>8.75</td>\n",
       "      <td>TRUEM-2430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ensemble Refinement</td>\n",
       "      <td>er_debate</td>\n",
       "      <td>er_few_shot</td>\n",
       "      <td>5:0 - self_consistency, PaLM</td>\n",
       "      <td>PaLM</td>\n",
       "      <td>0.46</td>\n",
       "      <td>6.36</td>\n",
       "      <td>TRUEM-2260</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.15</td>\n",
       "      <td>TRUEM-2458</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2.50</td>\n",
       "      <td>TRUEM-2428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ensemble Refinement</td>\n",
       "      <td>er_debate</td>\n",
       "      <td>er_few_shot + FS</td>\n",
       "      <td>3:9 - ER, GPT</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.54</td>\n",
       "      <td>76.60</td>\n",
       "      <td>TRUEM-2272</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.26</td>\n",
       "      <td>TRUEM-2470</td>\n",
       "      <td>0.74</td>\n",
       "      <td>33.21</td>\n",
       "      <td>TRUEM-2440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ensemble Refinement</td>\n",
       "      <td>er_debate</td>\n",
       "      <td>er_few_shot + FS</td>\n",
       "      <td>3:1 - ER, GPT</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.54</td>\n",
       "      <td>25.50</td>\n",
       "      <td>TRUEM-2270</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.42</td>\n",
       "      <td>TRUEM-2468</td>\n",
       "      <td>0.76</td>\n",
       "      <td>10.64</td>\n",
       "      <td>TRUEM-2438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Ensemble Refinement</td>\n",
       "      <td>er_debate</td>\n",
       "      <td>er_few_shot + FS</td>\n",
       "      <td>5:0 - self_consistency, GPT</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.54</td>\n",
       "      <td>31.86</td>\n",
       "      <td>TRUEM-2263</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.53</td>\n",
       "      <td>TRUEM-2461</td>\n",
       "      <td>0.71</td>\n",
       "      <td>13.04</td>\n",
       "      <td>TRUEM-2432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ensemble Refinement</td>\n",
       "      <td>er_debate</td>\n",
       "      <td>er_few_shot + FS</td>\n",
       "      <td>5:0 - self_consistency, PaLM</td>\n",
       "      <td>PaLM</td>\n",
       "      <td>0.47</td>\n",
       "      <td>9.57</td>\n",
       "      <td>TRUEM-2262</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.15</td>\n",
       "      <td>TRUEM-2460</td>\n",
       "      <td>0.71</td>\n",
       "      <td>4.30</td>\n",
       "      <td>TRUEM-2431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ensemble Refinement</td>\n",
       "      <td>er_debate_cot</td>\n",
       "      <td>er_cot</td>\n",
       "      <td>3:1 - ER, GPT</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.54</td>\n",
       "      <td>19.53</td>\n",
       "      <td>TRUEM-2265</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.44</td>\n",
       "      <td>TRUEM-2463</td>\n",
       "      <td>0.77</td>\n",
       "      <td>7.54</td>\n",
       "      <td>TRUEM-2433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ensemble Refinement</td>\n",
       "      <td>er_debate_cot</td>\n",
       "      <td>er_cot</td>\n",
       "      <td>5:0 - self_consistency, GPT</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.54</td>\n",
       "      <td>22.28</td>\n",
       "      <td>TRUEM-2257</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.53</td>\n",
       "      <td>TRUEM-2455</td>\n",
       "      <td>0.78</td>\n",
       "      <td>8.75</td>\n",
       "      <td>TRUEM-2425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ensemble Refinement</td>\n",
       "      <td>er_debate_cot</td>\n",
       "      <td>er_cot</td>\n",
       "      <td>3:9 - ER, GPT</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.55</td>\n",
       "      <td>69.00</td>\n",
       "      <td>TRUEM-2538</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.50</td>\n",
       "      <td>TRUEM-2465</td>\n",
       "      <td>0.75</td>\n",
       "      <td>25.60</td>\n",
       "      <td>TRUEM-2435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ensemble Refinement</td>\n",
       "      <td>er_debate_cot</td>\n",
       "      <td>er_cot</td>\n",
       "      <td>5:0 - self_consistency, PaLM</td>\n",
       "      <td>PaLM</td>\n",
       "      <td>0.17</td>\n",
       "      <td>6.36</td>\n",
       "      <td>TRUEM-2256</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.15</td>\n",
       "      <td>TRUEM-2454</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2.50</td>\n",
       "      <td>TRUEM-2424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Ensemble Refinement</td>\n",
       "      <td>er_debate_cot</td>\n",
       "      <td>er_cot + FS</td>\n",
       "      <td>5:0 - self_consistency, GPT</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.59</td>\n",
       "      <td>31.84</td>\n",
       "      <td>TRUEM-2259</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.75</td>\n",
       "      <td>TRUEM-2457</td>\n",
       "      <td>0.79</td>\n",
       "      <td>13.01</td>\n",
       "      <td>TRUEM-2427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Ensemble Refinement</td>\n",
       "      <td>er_debate_cot</td>\n",
       "      <td>er_cot + FS</td>\n",
       "      <td>3:9 - ER, GPT</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.60</td>\n",
       "      <td>83.03</td>\n",
       "      <td>TRUEM-2268</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.92</td>\n",
       "      <td>TRUEM-2466</td>\n",
       "      <td>0.78</td>\n",
       "      <td>37.22</td>\n",
       "      <td>TRUEM-2436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Ensemble Refinement</td>\n",
       "      <td>er_debate_cot</td>\n",
       "      <td>er_cot + FS</td>\n",
       "      <td>3:1 - ER, GPT</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.60</td>\n",
       "      <td>26.18</td>\n",
       "      <td>TRUEM-2266</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.61</td>\n",
       "      <td>TRUEM-2464</td>\n",
       "      <td>0.77</td>\n",
       "      <td>11.07</td>\n",
       "      <td>TRUEM-2434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ensemble Refinement</td>\n",
       "      <td>er_debate_cot</td>\n",
       "      <td>er_cot + FS</td>\n",
       "      <td>5:0 - self_consistency, PaLM</td>\n",
       "      <td>PaLM</td>\n",
       "      <td>0.52</td>\n",
       "      <td>9.56</td>\n",
       "      <td>TRUEM-2258</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.23</td>\n",
       "      <td>TRUEM-2456</td>\n",
       "      <td>0.72</td>\n",
       "      <td>4.29</td>\n",
       "      <td>TRUEM-2426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Multi-Persona</td>\n",
       "      <td>tsinghua_ma_debate</td>\n",
       "      <td>angel</td>\n",
       "      <td>2 rounds max</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.49</td>\n",
       "      <td>14.27</td>\n",
       "      <td>TRUEM-2320</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.33</td>\n",
       "      <td>TRUEM-2489</td>\n",
       "      <td>0.57</td>\n",
       "      <td>7.15</td>\n",
       "      <td>TRUEM-2402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Multi-Persona</td>\n",
       "      <td>tsinghua_ma_debate</td>\n",
       "      <td>angel</td>\n",
       "      <td>4 rounds max</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>14.70</td>\n",
       "      <td>TRUEM-2319</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.33</td>\n",
       "      <td>TRUEM-2491</td>\n",
       "      <td>0.60</td>\n",
       "      <td>9.52</td>\n",
       "      <td>TRUEM-2404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Multi-Persona</td>\n",
       "      <td>tsinghua_ma_debate</td>\n",
       "      <td>angel</td>\n",
       "      <td>3 rounds max</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.51</td>\n",
       "      <td>14.60</td>\n",
       "      <td>TRUEM-2318</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.34</td>\n",
       "      <td>TRUEM-2490</td>\n",
       "      <td>0.59</td>\n",
       "      <td>8.49</td>\n",
       "      <td>TRUEM-2403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Single Agent</td>\n",
       "      <td>-</td>\n",
       "      <td>cot</td>\n",
       "      <td>GPT</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.51</td>\n",
       "      <td>4.46</td>\n",
       "      <td>TRUEM-2245</td>\n",
       "      <td>0.65</td>\n",
       "      <td>3.82</td>\n",
       "      <td>TRUEM-2307</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.75</td>\n",
       "      <td>TRUEM-2389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Single Agent</td>\n",
       "      <td>-</td>\n",
       "      <td>cot</td>\n",
       "      <td>PaLM</td>\n",
       "      <td>PaLM</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.28</td>\n",
       "      <td>TRUEM-2248</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.03</td>\n",
       "      <td>TRUEM-2445</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.50</td>\n",
       "      <td>TRUEM-2388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Single Agent</td>\n",
       "      <td>-</td>\n",
       "      <td>er_cot</td>\n",
       "      <td>1:0 - single_agent, GPT</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.49</td>\n",
       "      <td>4.46</td>\n",
       "      <td>TRUEM-2249</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.11</td>\n",
       "      <td>TRUEM-2447</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.75</td>\n",
       "      <td>TRUEM-2479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Single Agent</td>\n",
       "      <td>-</td>\n",
       "      <td>er_cot</td>\n",
       "      <td>1:0 - single_agent, PaLM</td>\n",
       "      <td>PaLM</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.27</td>\n",
       "      <td>TRUEM-2247</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.03</td>\n",
       "      <td>TRUEM-2442</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.50</td>\n",
       "      <td>TRUEM-2505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Single Agent</td>\n",
       "      <td>-</td>\n",
       "      <td>er_cot + FS</td>\n",
       "      <td>1:0 - single_agent, GPT</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.56</td>\n",
       "      <td>6.37</td>\n",
       "      <td>TRUEM-2251</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.15</td>\n",
       "      <td>TRUEM-2449</td>\n",
       "      <td>0.79</td>\n",
       "      <td>2.60</td>\n",
       "      <td>TRUEM-2417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Single Agent</td>\n",
       "      <td>-</td>\n",
       "      <td>er_cot + FS</td>\n",
       "      <td>1:0 - single_agent, PaLM</td>\n",
       "      <td>PaLM</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.91</td>\n",
       "      <td>TRUEM-2250</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.04</td>\n",
       "      <td>TRUEM-2448</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.86</td>\n",
       "      <td>TRUEM-2513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Single Agent</td>\n",
       "      <td>-</td>\n",
       "      <td>er_few_shot</td>\n",
       "      <td>1:0 - single_agent, GPT</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.53</td>\n",
       "      <td>4.46</td>\n",
       "      <td>TRUEM-2253</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.11</td>\n",
       "      <td>TRUEM-2451</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1.75</td>\n",
       "      <td>TRUEM-2421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Single Agent</td>\n",
       "      <td>-</td>\n",
       "      <td>er_few_shot</td>\n",
       "      <td>1:0 - single_agent, PaLM</td>\n",
       "      <td>PaLM</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1.27</td>\n",
       "      <td>TRUEM-2252</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.03</td>\n",
       "      <td>TRUEM-2450</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>TRUEM-2419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Single Agent</td>\n",
       "      <td>-</td>\n",
       "      <td>er_few_shot + FS</td>\n",
       "      <td>1:0 - single_agent, GPT</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.54</td>\n",
       "      <td>6.37</td>\n",
       "      <td>TRUEM-2255</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.11</td>\n",
       "      <td>TRUEM-2453</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.61</td>\n",
       "      <td>TRUEM-2423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Single Agent</td>\n",
       "      <td>-</td>\n",
       "      <td>er_few_shot + FS</td>\n",
       "      <td>1:0 - single_agent, PaLM</td>\n",
       "      <td>PaLM</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.91</td>\n",
       "      <td>TRUEM-2254</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.03</td>\n",
       "      <td>TRUEM-2452</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.86</td>\n",
       "      <td>TRUEM-2422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Single Agent</td>\n",
       "      <td>-</td>\n",
       "      <td>simple</td>\n",
       "      <td>GPT</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.52</td>\n",
       "      <td>4.46</td>\n",
       "      <td>TRUEM-2415</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.11</td>\n",
       "      <td>TRUEM-2443</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1.75</td>\n",
       "      <td>TRUEM-2387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Single Agent</td>\n",
       "      <td>-</td>\n",
       "      <td>simple</td>\n",
       "      <td>PaLM</td>\n",
       "      <td>PaLM</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1.27</td>\n",
       "      <td>TRUEM-2279</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.09</td>\n",
       "      <td>TRUEM-2308</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.50</td>\n",
       "      <td>TRUEM-2386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Single Agent</td>\n",
       "      <td>-</td>\n",
       "      <td>spp_original</td>\n",
       "      <td>SPP Synergy</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.53</td>\n",
       "      <td>6.38</td>\n",
       "      <td>TRUEM-2264</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.04</td>\n",
       "      <td>TRUEM-2501</td>\n",
       "      <td>0.69</td>\n",
       "      <td>2.55</td>\n",
       "      <td>TRUEM-2385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Society of Mind</td>\n",
       "      <td>google_ma_debate</td>\n",
       "      <td>cot</td>\n",
       "      <td>2 agents, 2 rounds, summarized answers</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.57</td>\n",
       "      <td>17.83</td>\n",
       "      <td>TRUEM-2273</td>\n",
       "      <td>0.69</td>\n",
       "      <td>15.26</td>\n",
       "      <td>TRUEM-2311</td>\n",
       "      <td>0.73</td>\n",
       "      <td>7.00</td>\n",
       "      <td>TRUEM-2390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Society of Mind</td>\n",
       "      <td>google_ma_debate</td>\n",
       "      <td>cot</td>\n",
       "      <td>2 agents, 2 rounds</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.58</td>\n",
       "      <td>18.05</td>\n",
       "      <td>TRUEM-2291</td>\n",
       "      <td>0.67</td>\n",
       "      <td>15.26</td>\n",
       "      <td>TRUEM-2325</td>\n",
       "      <td>0.76</td>\n",
       "      <td>7.00</td>\n",
       "      <td>TRUEM-2396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Society of Mind</td>\n",
       "      <td>google_ma_debate</td>\n",
       "      <td>cot</td>\n",
       "      <td>3 agents, 3 rounds</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.59</td>\n",
       "      <td>41.94</td>\n",
       "      <td>TRUEM-2411</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.95</td>\n",
       "      <td>TRUEM-2486</td>\n",
       "      <td>0.76</td>\n",
       "      <td>15.80</td>\n",
       "      <td>TRUEM-2399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Society of Mind</td>\n",
       "      <td>google_ma_debate</td>\n",
       "      <td>cot</td>\n",
       "      <td>2 agents, 3 rounds</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.59</td>\n",
       "      <td>26.94</td>\n",
       "      <td>TRUEM-2292</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.63</td>\n",
       "      <td>TRUEM-2484</td>\n",
       "      <td>0.76</td>\n",
       "      <td>10.50</td>\n",
       "      <td>TRUEM-2397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Society of Mind</td>\n",
       "      <td>google_ma_debate</td>\n",
       "      <td>cot</td>\n",
       "      <td>4 agents, 2 rounds, summarized answers</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.59</td>\n",
       "      <td>35.65</td>\n",
       "      <td>TRUEM-2287</td>\n",
       "      <td>0.71</td>\n",
       "      <td>30.52</td>\n",
       "      <td>TRUEM-2323</td>\n",
       "      <td>0.77</td>\n",
       "      <td>14.00</td>\n",
       "      <td>TRUEM-2394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Society of Mind</td>\n",
       "      <td>google_ma_debate</td>\n",
       "      <td>cot</td>\n",
       "      <td>3 agents, 2 rounds, summarized answers</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.59</td>\n",
       "      <td>26.74</td>\n",
       "      <td>TRUEM-2284</td>\n",
       "      <td>0.70</td>\n",
       "      <td>22.89</td>\n",
       "      <td>TRUEM-2321</td>\n",
       "      <td>0.76</td>\n",
       "      <td>10.50</td>\n",
       "      <td>TRUEM-2392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Society of Mind</td>\n",
       "      <td>google_ma_debate</td>\n",
       "      <td>cot</td>\n",
       "      <td>4 agents, 2 rounds</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.60</td>\n",
       "      <td>38.96</td>\n",
       "      <td>TRUEM-2413</td>\n",
       "      <td>0.70</td>\n",
       "      <td>30.81</td>\n",
       "      <td>TRUEM-2351</td>\n",
       "      <td>0.74</td>\n",
       "      <td>14.02</td>\n",
       "      <td>TRUEM-2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Society of Mind</td>\n",
       "      <td>google_ma_debate</td>\n",
       "      <td>cot</td>\n",
       "      <td>2 agents, 3 rounds, summarized answers</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.60</td>\n",
       "      <td>26.74</td>\n",
       "      <td>TRUEM-2282</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.63</td>\n",
       "      <td>TRUEM-2472</td>\n",
       "      <td>0.74</td>\n",
       "      <td>10.51</td>\n",
       "      <td>TRUEM-2391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Society of Mind</td>\n",
       "      <td>google_ma_debate</td>\n",
       "      <td>cot</td>\n",
       "      <td>4 agents, 3 rounds</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.61</td>\n",
       "      <td>58.52</td>\n",
       "      <td>TRUEM-2412</td>\n",
       "      <td>0.70</td>\n",
       "      <td>46.32</td>\n",
       "      <td>TRUEM-2356</td>\n",
       "      <td>0.74</td>\n",
       "      <td>21.40</td>\n",
       "      <td>TRUEM-2401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Society of Mind</td>\n",
       "      <td>google_ma_debate</td>\n",
       "      <td>cot</td>\n",
       "      <td>3 agents, 2 rounds</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.61</td>\n",
       "      <td>28.04</td>\n",
       "      <td>TRUEM-2293</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.63</td>\n",
       "      <td>TRUEM-2485</td>\n",
       "      <td>0.75</td>\n",
       "      <td>10.50</td>\n",
       "      <td>TRUEM-2398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Society of Mind</td>\n",
       "      <td>google_ma_debate</td>\n",
       "      <td>cot</td>\n",
       "      <td>4 agents, 3 rounds, summarized answers</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.61</td>\n",
       "      <td>53.48</td>\n",
       "      <td>TRUEM-2290</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.26</td>\n",
       "      <td>TRUEM-2482</td>\n",
       "      <td>0.72</td>\n",
       "      <td>21.01</td>\n",
       "      <td>TRUEM-2395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Society of Mind</td>\n",
       "      <td>google_ma_debate</td>\n",
       "      <td>cot</td>\n",
       "      <td>3 agents, 3 rounds, summarized answers</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.61</td>\n",
       "      <td>40.11</td>\n",
       "      <td>TRUEM-2286</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.94</td>\n",
       "      <td>TRUEM-2480</td>\n",
       "      <td>0.72</td>\n",
       "      <td>15.75</td>\n",
       "      <td>TRUEM-2393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            System Name       Debate Prompt      Agent Prompt  \\\n",
       "0              ChatEval  chateval_ma_debate               cot   \n",
       "1              ChatEval  chateval_ma_debate               cot   \n",
       "2              ChatEval  chateval_ma_debate               cot   \n",
       "3              ChatEval  chateval_ma_debate               cot   \n",
       "4              ChatEval  chateval_ma_debate               cot   \n",
       "5              ChatEval  chateval_ma_debate               cot   \n",
       "6   Ensemble Refinement           er_debate       er_few_shot   \n",
       "7   Ensemble Refinement           er_debate       er_few_shot   \n",
       "8   Ensemble Refinement           er_debate       er_few_shot   \n",
       "9   Ensemble Refinement           er_debate       er_few_shot   \n",
       "10  Ensemble Refinement           er_debate  er_few_shot + FS   \n",
       "11  Ensemble Refinement           er_debate  er_few_shot + FS   \n",
       "12  Ensemble Refinement           er_debate  er_few_shot + FS   \n",
       "13  Ensemble Refinement           er_debate  er_few_shot + FS   \n",
       "14  Ensemble Refinement       er_debate_cot            er_cot   \n",
       "15  Ensemble Refinement       er_debate_cot            er_cot   \n",
       "16  Ensemble Refinement       er_debate_cot            er_cot   \n",
       "17  Ensemble Refinement       er_debate_cot            er_cot   \n",
       "18  Ensemble Refinement       er_debate_cot       er_cot + FS   \n",
       "19  Ensemble Refinement       er_debate_cot       er_cot + FS   \n",
       "20  Ensemble Refinement       er_debate_cot       er_cot + FS   \n",
       "21  Ensemble Refinement       er_debate_cot       er_cot + FS   \n",
       "22        Multi-Persona  tsinghua_ma_debate             angel   \n",
       "23        Multi-Persona  tsinghua_ma_debate             angel   \n",
       "24        Multi-Persona  tsinghua_ma_debate             angel   \n",
       "25         Single Agent                   -               cot   \n",
       "26         Single Agent                   -               cot   \n",
       "27         Single Agent                   -            er_cot   \n",
       "28         Single Agent                   -            er_cot   \n",
       "29         Single Agent                   -       er_cot + FS   \n",
       "30         Single Agent                   -       er_cot + FS   \n",
       "31         Single Agent                   -       er_few_shot   \n",
       "32         Single Agent                   -       er_few_shot   \n",
       "33         Single Agent                   -  er_few_shot + FS   \n",
       "34         Single Agent                   -  er_few_shot + FS   \n",
       "35         Single Agent                   -            simple   \n",
       "36         Single Agent                   -            simple   \n",
       "37         Single Agent                   -      spp_original   \n",
       "38      Society of Mind    google_ma_debate               cot   \n",
       "39      Society of Mind    google_ma_debate               cot   \n",
       "40      Society of Mind    google_ma_debate               cot   \n",
       "41      Society of Mind    google_ma_debate               cot   \n",
       "42      Society of Mind    google_ma_debate               cot   \n",
       "43      Society of Mind    google_ma_debate               cot   \n",
       "44      Society of Mind    google_ma_debate               cot   \n",
       "45      Society of Mind    google_ma_debate               cot   \n",
       "46      Society of Mind    google_ma_debate               cot   \n",
       "47      Society of Mind    google_ma_debate               cot   \n",
       "48      Society of Mind    google_ma_debate               cot   \n",
       "49      Society of Mind    google_ma_debate               cot   \n",
       "\n",
       "                                         Config  Agents  Score (MEDQA)  \\\n",
       "0                          3 rounds, one_by_one  GPT3.5           0.53   \n",
       "1                   2 rounds, simultaneous_talk  GPT3.5           0.54   \n",
       "2   3 rounds, simultaneous_talk_with_summarizer  GPT3.5           0.55   \n",
       "3                          2 rounds, one_by_one  GPT3.5           0.55   \n",
       "4   2 rounds, simultaneous_talk_with_summarizer  GPT3.5           0.55   \n",
       "5                   3 rounds, simultaneous_talk  GPT3.5           0.57   \n",
       "6                                 3:9 - ER, GPT  GPT3.5           0.53   \n",
       "7                                 3:1 - ER, GPT  GPT3.5           0.53   \n",
       "8                   5:0 - self_consistency, GPT  GPT3.5           0.53   \n",
       "9                  5:0 - self_consistency, PaLM    PaLM           0.46   \n",
       "10                                3:9 - ER, GPT  GPT3.5           0.54   \n",
       "11                                3:1 - ER, GPT  GPT3.5           0.54   \n",
       "12                  5:0 - self_consistency, GPT  GPT3.5           0.54   \n",
       "13                 5:0 - self_consistency, PaLM    PaLM           0.47   \n",
       "14                                3:1 - ER, GPT  GPT3.5           0.54   \n",
       "15                  5:0 - self_consistency, GPT  GPT3.5           0.54   \n",
       "16                                3:9 - ER, GPT  GPT3.5           0.55   \n",
       "17                 5:0 - self_consistency, PaLM    PaLM           0.17   \n",
       "18                  5:0 - self_consistency, GPT  GPT3.5           0.59   \n",
       "19                                3:9 - ER, GPT  GPT3.5           0.60   \n",
       "20                                3:1 - ER, GPT  GPT3.5           0.60   \n",
       "21                 5:0 - self_consistency, PaLM    PaLM           0.52   \n",
       "22                                 2 rounds max  GPT3.5           0.49   \n",
       "23                                 4 rounds max  GPT3.5           0.50   \n",
       "24                                 3 rounds max  GPT3.5           0.51   \n",
       "25                                          GPT  GPT3.5           0.51   \n",
       "26                                         PaLM    PaLM           0.14   \n",
       "27                      1:0 - single_agent, GPT  GPT3.5           0.49   \n",
       "28                     1:0 - single_agent, PaLM    PaLM           0.17   \n",
       "29                      1:0 - single_agent, GPT  GPT3.5           0.56   \n",
       "30                     1:0 - single_agent, PaLM    PaLM           0.49   \n",
       "31                      1:0 - single_agent, GPT  GPT3.5           0.53   \n",
       "32                     1:0 - single_agent, PaLM    PaLM           0.46   \n",
       "33                      1:0 - single_agent, GPT  GPT3.5           0.54   \n",
       "34                     1:0 - single_agent, PaLM    PaLM           0.47   \n",
       "35                                          GPT  GPT3.5           0.52   \n",
       "36                                         PaLM    PaLM           0.46   \n",
       "37                                  SPP Synergy  GPT3.5           0.53   \n",
       "38       2 agents, 2 rounds, summarized answers  GPT3.5           0.57   \n",
       "39                           2 agents, 2 rounds  GPT3.5           0.58   \n",
       "40                           3 agents, 3 rounds  GPT3.5           0.59   \n",
       "41                           2 agents, 3 rounds  GPT3.5           0.59   \n",
       "42       4 agents, 2 rounds, summarized answers  GPT3.5           0.59   \n",
       "43       3 agents, 2 rounds, summarized answers  GPT3.5           0.59   \n",
       "44                           4 agents, 2 rounds  GPT3.5           0.60   \n",
       "45       2 agents, 3 rounds, summarized answers  GPT3.5           0.60   \n",
       "46                           4 agents, 3 rounds  GPT3.5           0.61   \n",
       "47                           3 agents, 2 rounds  GPT3.5           0.61   \n",
       "48       4 agents, 3 rounds, summarized answers  GPT3.5           0.61   \n",
       "49       3 agents, 3 rounds, summarized answers  GPT3.5           0.61   \n",
       "\n",
       "    Cost \\$ (MEDQA)  ID (MEDQA)  Score (MMLU)  Cost \\$ (MMLU)   ID (MMLU)  \\\n",
       "0             34.81  TRUEM-2441          0.70            0.73  TRUEM-2493   \n",
       "1             19.90  TRUEM-2302          0.73            0.43  TRUEM-2494   \n",
       "2             36.78  TRUEM-2429          0.73            0.84  TRUEM-2497   \n",
       "3             20.55  TRUEM-2414          0.69           16.28  TRUEM-2362   \n",
       "4             22.58  TRUEM-2304          0.70            0.53  TRUEM-2496   \n",
       "5             33.26  TRUEM-2303          0.83            0.72  TRUEM-2495   \n",
       "6             53.57  TRUEM-2271          0.63            1.26  TRUEM-2469   \n",
       "7             17.83  TRUEM-2269          0.67            0.42  TRUEM-2467   \n",
       "8             22.28  TRUEM-2261          0.70            0.53  TRUEM-2459   \n",
       "9              6.36  TRUEM-2260          0.50            0.15  TRUEM-2458   \n",
       "10            76.60  TRUEM-2272          0.83            1.26  TRUEM-2470   \n",
       "11            25.50  TRUEM-2270          0.83            0.42  TRUEM-2468   \n",
       "12            31.86  TRUEM-2263          0.73            0.53  TRUEM-2461   \n",
       "13             9.57  TRUEM-2262          0.63            0.15  TRUEM-2460   \n",
       "14            19.53  TRUEM-2265          0.70            0.44  TRUEM-2463   \n",
       "15            22.28  TRUEM-2257          0.70            0.53  TRUEM-2455   \n",
       "16            69.00  TRUEM-2538          0.67            1.50  TRUEM-2465   \n",
       "17             6.36  TRUEM-2256          0.33            0.15  TRUEM-2454   \n",
       "18            31.84  TRUEM-2259          0.70            0.75  TRUEM-2457   \n",
       "19            83.03  TRUEM-2268          0.73            1.92  TRUEM-2466   \n",
       "20            26.18  TRUEM-2266          0.77            0.61  TRUEM-2464   \n",
       "21             9.56  TRUEM-2258          0.63            0.23  TRUEM-2456   \n",
       "22            14.27  TRUEM-2320          0.63            0.33  TRUEM-2489   \n",
       "23            14.70  TRUEM-2319          0.67            0.33  TRUEM-2491   \n",
       "24            14.60  TRUEM-2318          0.63            0.34  TRUEM-2490   \n",
       "25             4.46  TRUEM-2245          0.65            3.82  TRUEM-2307   \n",
       "26             1.28  TRUEM-2248          0.30            0.03  TRUEM-2445   \n",
       "27             4.46  TRUEM-2249          0.67            0.11  TRUEM-2447   \n",
       "28             1.27  TRUEM-2247          0.33            0.03  TRUEM-2442   \n",
       "29             6.37  TRUEM-2251          0.70            0.15  TRUEM-2449   \n",
       "30             1.91  TRUEM-2250          0.63            0.04  TRUEM-2448   \n",
       "31             4.46  TRUEM-2253          0.70            0.11  TRUEM-2451   \n",
       "32             1.27  TRUEM-2252          0.50            0.03  TRUEM-2450   \n",
       "33             6.37  TRUEM-2255          0.80            0.11  TRUEM-2453   \n",
       "34             1.91  TRUEM-2254          0.70            0.03  TRUEM-2452   \n",
       "35             4.46  TRUEM-2415          0.73            0.11  TRUEM-2443   \n",
       "36             1.27  TRUEM-2279          0.68            1.09  TRUEM-2308   \n",
       "37             6.38  TRUEM-2264          0.70            0.04  TRUEM-2501   \n",
       "38            17.83  TRUEM-2273          0.69           15.26  TRUEM-2311   \n",
       "39            18.05  TRUEM-2291          0.67           15.26  TRUEM-2325   \n",
       "40            41.94  TRUEM-2411          0.63            0.95  TRUEM-2486   \n",
       "41            26.94  TRUEM-2292          0.73            0.63  TRUEM-2484   \n",
       "42            35.65  TRUEM-2287          0.71           30.52  TRUEM-2323   \n",
       "43            26.74  TRUEM-2284          0.70           22.89  TRUEM-2321   \n",
       "44            38.96  TRUEM-2413          0.70           30.81  TRUEM-2351   \n",
       "45            26.74  TRUEM-2282          0.73            0.63  TRUEM-2472   \n",
       "46            58.52  TRUEM-2412          0.70           46.32  TRUEM-2356   \n",
       "47            28.04  TRUEM-2293          0.73            0.63  TRUEM-2485   \n",
       "48            53.48  TRUEM-2290          0.77            1.26  TRUEM-2482   \n",
       "49            40.11  TRUEM-2286          0.67            0.94  TRUEM-2480   \n",
       "\n",
       "    Score (PUBMEDQA)  Cost \\$ (PUBMEDQA) ID (PUBMEDQA)  \n",
       "0               0.76               12.60    TRUEM-2406  \n",
       "1               0.74                7.27    TRUEM-2407  \n",
       "2               0.77               14.01    TRUEM-2410  \n",
       "3               0.76                7.64    TRUEM-2405  \n",
       "4               0.72                8.76    TRUEM-2409  \n",
       "5               0.77               12.14    TRUEM-2408  \n",
       "6               0.72               21.00    TRUEM-2439  \n",
       "7               0.72                7.00    TRUEM-2437  \n",
       "8               0.70                8.75    TRUEM-2430  \n",
       "9               0.76                2.50    TRUEM-2428  \n",
       "10              0.74               33.21    TRUEM-2440  \n",
       "11              0.76               10.64    TRUEM-2438  \n",
       "12              0.71               13.04    TRUEM-2432  \n",
       "13              0.71                4.30    TRUEM-2431  \n",
       "14              0.77                7.54    TRUEM-2433  \n",
       "15              0.78                8.75    TRUEM-2425  \n",
       "16              0.75               25.60    TRUEM-2435  \n",
       "17              0.38                2.50    TRUEM-2424  \n",
       "18              0.79               13.01    TRUEM-2427  \n",
       "19              0.78               37.22    TRUEM-2436  \n",
       "20              0.77               11.07    TRUEM-2434  \n",
       "21              0.72                4.29    TRUEM-2426  \n",
       "22              0.57                7.15    TRUEM-2402  \n",
       "23              0.60                9.52    TRUEM-2404  \n",
       "24              0.59                8.49    TRUEM-2403  \n",
       "25              0.77                1.75    TRUEM-2389  \n",
       "26              0.42                0.50    TRUEM-2388  \n",
       "27              0.74                1.75    TRUEM-2479  \n",
       "28              0.38                0.50    TRUEM-2505  \n",
       "29              0.79                2.60    TRUEM-2417  \n",
       "30              0.71                0.86    TRUEM-2513  \n",
       "31              0.71                1.75    TRUEM-2421  \n",
       "32              0.75                0.50    TRUEM-2419  \n",
       "33              0.70                2.61    TRUEM-2423  \n",
       "34              0.65                0.86    TRUEM-2422  \n",
       "35              0.71                1.75    TRUEM-2387  \n",
       "36              0.76                0.50    TRUEM-2386  \n",
       "37              0.69                2.55    TRUEM-2385  \n",
       "38              0.73                7.00    TRUEM-2390  \n",
       "39              0.76                7.00    TRUEM-2396  \n",
       "40              0.76               15.80    TRUEM-2399  \n",
       "41              0.76               10.50    TRUEM-2397  \n",
       "42              0.77               14.00    TRUEM-2394  \n",
       "43              0.76               10.50    TRUEM-2392  \n",
       "44              0.74               14.02    TRUEM-2400  \n",
       "45              0.74               10.51    TRUEM-2391  \n",
       "46              0.74               21.40    TRUEM-2401  \n",
       "47              0.75               10.50    TRUEM-2398  \n",
       "48              0.72               21.01    TRUEM-2395  \n",
       "49              0.72               15.75    TRUEM-2393  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = merged[['System Name', 'Debate Prompt', 'Agent Prompt', 'Config', 'Agents', 'Score (MEDQA)', 'Cost \\$ (MEDQA)', 'ID (MEDQA)', 'Score (MMLU)', 'Cost \\$ (MMLU)', 'ID (MMLU)', 'Score (PUBMEDQA)', 'Cost \\$ (PUBMEDQA)', 'ID (PUBMEDQA)']]\n",
    "# merged = merged[['System Name', 'Debate Prompt', 'Agent Prompt', 'Config', 'Agents', 'Score (MEDQA)', 'Cost \\$ (MEDQA)', 'Score (MMLU)', 'Cost \\$ (MMLU)', 'Score (PUBMEDQA)', 'Cost \\$ (PUBMEDQA)']]\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48edbe7-9ab5-4476-a9bd-1dbb8a7739a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv(\"file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e4dc2c-d0bf-4b2e-b563-39eb6e08c60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc854be-9121-4100-8192-8815fa868bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "debate_prompts = {\n",
    "    \"chateval_ma_debate\":\"CE MAD\",\n",
    "    \"er_debate\" : \"ER MAD\",\n",
    "    \"er_debate\" : \"ER MAD\",\n",
    "    \"er_debate_cot\" : \"ER MAD CoT\", \n",
    "    \"tsinghua_ma_debate\" : \"MP MAD\",\n",
    "    \"-\" : \"-\",\n",
    "    \"google_ma_debate\" : \"SoM MAD\"    \n",
    "}\n",
    "agent_prompts={\"cot\": \"CoT\",\n",
    "               \"er_few_shot\" : \"FS\",\n",
    "               \"er_few_shot + FS\" : \"FS+EG\",\n",
    "               \"er_cot\": \"CoT\",\n",
    "               \"er_cot + FS\": \"FS-CoT\",\n",
    "               \"angel\" : \"ANGEL+DEVIL\",\n",
    "               \"cot\": \"CoT\",\n",
    "               \"simple\": \"SIMPLE\",\n",
    "               \"spp_original\" : \"SPP\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacb5372-2732-4c9c-96a9-eb09f6156a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Debate Prompt\"] = df[\"Debate Prompt\"].map(lambda x: debate_prompts[x])\n",
    "df[\"Agent Prompt\"] = df[\"Agent Prompt\"].map(lambda x: agent_prompts[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb047925-116f-4a87-a772-862baf192856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System Name</th>\n",
       "      <th>Debate Prompt</th>\n",
       "      <th>Agent Prompt</th>\n",
       "      <th>Config</th>\n",
       "      <th>Agents</th>\n",
       "      <th>Score (MEDQA)</th>\n",
       "      <th>Cost \\$ (MEDQA)</th>\n",
       "      <th>ID (MEDQA)</th>\n",
       "      <th>Score (MMLU)</th>\n",
       "      <th>Cost \\$ (MMLU)</th>\n",
       "      <th>ID (MMLU)</th>\n",
       "      <th>Score (PUBMEDQA)</th>\n",
       "      <th>Cost \\$ (PUBMEDQA)</th>\n",
       "      <th>ID (PUBMEDQA)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Single Agent</td>\n",
       "      <td>-</td>\n",
       "      <td>CoT</td>\n",
       "      <td></td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.51</td>\n",
       "      <td>4.46</td>\n",
       "      <td>TRUEM-2245</td>\n",
       "      <td>0.65</td>\n",
       "      <td>3.82</td>\n",
       "      <td>TRUEM-2307</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.75</td>\n",
       "      <td>TRUEM-2389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Single Agent</td>\n",
       "      <td>-</td>\n",
       "      <td>CoT</td>\n",
       "      <td></td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.49</td>\n",
       "      <td>4.46</td>\n",
       "      <td>TRUEM-2249</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.11</td>\n",
       "      <td>TRUEM-2447</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.75</td>\n",
       "      <td>TRUEM-2479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Single Agent</td>\n",
       "      <td>-</td>\n",
       "      <td>CoT</td>\n",
       "      <td></td>\n",
       "      <td>PaLM</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.28</td>\n",
       "      <td>TRUEM-2248</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.03</td>\n",
       "      <td>TRUEM-2445</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.50</td>\n",
       "      <td>TRUEM-2388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Single Agent</td>\n",
       "      <td>-</td>\n",
       "      <td>CoT</td>\n",
       "      <td></td>\n",
       "      <td>PaLM</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.27</td>\n",
       "      <td>TRUEM-2247</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.03</td>\n",
       "      <td>TRUEM-2442</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.50</td>\n",
       "      <td>TRUEM-2505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Single Agent</td>\n",
       "      <td>-</td>\n",
       "      <td>FS</td>\n",
       "      <td></td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.53</td>\n",
       "      <td>4.46</td>\n",
       "      <td>TRUEM-2253</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.11</td>\n",
       "      <td>TRUEM-2451</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1.75</td>\n",
       "      <td>TRUEM-2421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Single Agent</td>\n",
       "      <td>-</td>\n",
       "      <td>FS</td>\n",
       "      <td></td>\n",
       "      <td>PaLM</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1.27</td>\n",
       "      <td>TRUEM-2252</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.03</td>\n",
       "      <td>TRUEM-2450</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>TRUEM-2419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Single Agent</td>\n",
       "      <td>-</td>\n",
       "      <td>FS+EG</td>\n",
       "      <td></td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.54</td>\n",
       "      <td>6.37</td>\n",
       "      <td>TRUEM-2255</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.11</td>\n",
       "      <td>TRUEM-2453</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.61</td>\n",
       "      <td>TRUEM-2423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Single Agent</td>\n",
       "      <td>-</td>\n",
       "      <td>FS+EG</td>\n",
       "      <td></td>\n",
       "      <td>PaLM</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.91</td>\n",
       "      <td>TRUEM-2254</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.03</td>\n",
       "      <td>TRUEM-2452</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.86</td>\n",
       "      <td>TRUEM-2422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Single Agent</td>\n",
       "      <td>-</td>\n",
       "      <td>FS-CoT</td>\n",
       "      <td></td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.56</td>\n",
       "      <td>6.37</td>\n",
       "      <td>TRUEM-2251</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.15</td>\n",
       "      <td>TRUEM-2449</td>\n",
       "      <td>0.79</td>\n",
       "      <td>2.60</td>\n",
       "      <td>TRUEM-2417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Single Agent</td>\n",
       "      <td>-</td>\n",
       "      <td>FS-CoT</td>\n",
       "      <td></td>\n",
       "      <td>PaLM</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.91</td>\n",
       "      <td>TRUEM-2250</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.04</td>\n",
       "      <td>TRUEM-2448</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.86</td>\n",
       "      <td>TRUEM-2513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Single Agent</td>\n",
       "      <td>-</td>\n",
       "      <td>SIMPLE</td>\n",
       "      <td></td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.52</td>\n",
       "      <td>4.46</td>\n",
       "      <td>TRUEM-2415</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.11</td>\n",
       "      <td>TRUEM-2443</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1.75</td>\n",
       "      <td>TRUEM-2387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Single Agent</td>\n",
       "      <td>-</td>\n",
       "      <td>SIMPLE</td>\n",
       "      <td></td>\n",
       "      <td>PaLM</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1.27</td>\n",
       "      <td>TRUEM-2279</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.09</td>\n",
       "      <td>TRUEM-2308</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.50</td>\n",
       "      <td>TRUEM-2386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Single Agent</td>\n",
       "      <td>-</td>\n",
       "      <td>SPP</td>\n",
       "      <td>SPP Synergy</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.53</td>\n",
       "      <td>6.38</td>\n",
       "      <td>TRUEM-2264</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.04</td>\n",
       "      <td>TRUEM-2501</td>\n",
       "      <td>0.69</td>\n",
       "      <td>2.55</td>\n",
       "      <td>TRUEM-2385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ChatEval</td>\n",
       "      <td>CE MAD</td>\n",
       "      <td>CoT</td>\n",
       "      <td>3 rounds, one by one</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.53</td>\n",
       "      <td>34.81</td>\n",
       "      <td>TRUEM-2441</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.73</td>\n",
       "      <td>TRUEM-2493</td>\n",
       "      <td>0.76</td>\n",
       "      <td>12.60</td>\n",
       "      <td>TRUEM-2406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ChatEval</td>\n",
       "      <td>CE MAD</td>\n",
       "      <td>CoT</td>\n",
       "      <td>2 rounds, simultaneous talk</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.54</td>\n",
       "      <td>19.90</td>\n",
       "      <td>TRUEM-2302</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.43</td>\n",
       "      <td>TRUEM-2494</td>\n",
       "      <td>0.74</td>\n",
       "      <td>7.27</td>\n",
       "      <td>TRUEM-2407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ChatEval</td>\n",
       "      <td>CE MAD</td>\n",
       "      <td>CoT</td>\n",
       "      <td>3 rounds, simultaneous talk with summarizer</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.55</td>\n",
       "      <td>36.78</td>\n",
       "      <td>TRUEM-2429</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.84</td>\n",
       "      <td>TRUEM-2497</td>\n",
       "      <td>0.77</td>\n",
       "      <td>14.01</td>\n",
       "      <td>TRUEM-2410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ChatEval</td>\n",
       "      <td>CE MAD</td>\n",
       "      <td>CoT</td>\n",
       "      <td>2 rounds, one by one</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.55</td>\n",
       "      <td>20.55</td>\n",
       "      <td>TRUEM-2414</td>\n",
       "      <td>0.69</td>\n",
       "      <td>16.28</td>\n",
       "      <td>TRUEM-2362</td>\n",
       "      <td>0.76</td>\n",
       "      <td>7.64</td>\n",
       "      <td>TRUEM-2405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ChatEval</td>\n",
       "      <td>CE MAD</td>\n",
       "      <td>CoT</td>\n",
       "      <td>2 rounds, simultaneous talk with summarizer</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.55</td>\n",
       "      <td>22.58</td>\n",
       "      <td>TRUEM-2304</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.53</td>\n",
       "      <td>TRUEM-2496</td>\n",
       "      <td>0.72</td>\n",
       "      <td>8.76</td>\n",
       "      <td>TRUEM-2409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ChatEval</td>\n",
       "      <td>CE MAD</td>\n",
       "      <td>CoT</td>\n",
       "      <td>3 rounds, simultaneous talk</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.57</td>\n",
       "      <td>33.26</td>\n",
       "      <td>TRUEM-2303</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.72</td>\n",
       "      <td>TRUEM-2495</td>\n",
       "      <td>0.77</td>\n",
       "      <td>12.14</td>\n",
       "      <td>TRUEM-2408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ensemble Refinement</td>\n",
       "      <td>ER MAD</td>\n",
       "      <td>FS</td>\n",
       "      <td>reasoning=3, aggregation=9</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.53</td>\n",
       "      <td>53.57</td>\n",
       "      <td>TRUEM-2271</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.26</td>\n",
       "      <td>TRUEM-2469</td>\n",
       "      <td>0.72</td>\n",
       "      <td>21.00</td>\n",
       "      <td>TRUEM-2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ensemble Refinement</td>\n",
       "      <td>ER MAD</td>\n",
       "      <td>FS</td>\n",
       "      <td>reasoning=3, aggregation=1</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.53</td>\n",
       "      <td>17.83</td>\n",
       "      <td>TRUEM-2269</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.42</td>\n",
       "      <td>TRUEM-2467</td>\n",
       "      <td>0.72</td>\n",
       "      <td>7.00</td>\n",
       "      <td>TRUEM-2437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ensemble Refinement</td>\n",
       "      <td>ER MAD</td>\n",
       "      <td>FS</td>\n",
       "      <td>self consistency: reasoning=5</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.53</td>\n",
       "      <td>22.28</td>\n",
       "      <td>TRUEM-2261</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.53</td>\n",
       "      <td>TRUEM-2459</td>\n",
       "      <td>0.70</td>\n",
       "      <td>8.75</td>\n",
       "      <td>TRUEM-2430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ensemble Refinement</td>\n",
       "      <td>ER MAD</td>\n",
       "      <td>FS</td>\n",
       "      <td>self consistency: reasoning=5</td>\n",
       "      <td>PaLM</td>\n",
       "      <td>0.46</td>\n",
       "      <td>6.36</td>\n",
       "      <td>TRUEM-2260</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.15</td>\n",
       "      <td>TRUEM-2458</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2.50</td>\n",
       "      <td>TRUEM-2428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ensemble Refinement</td>\n",
       "      <td>ER MAD</td>\n",
       "      <td>FS+EG</td>\n",
       "      <td>reasoning=3, aggregation=9</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.54</td>\n",
       "      <td>76.60</td>\n",
       "      <td>TRUEM-2272</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.26</td>\n",
       "      <td>TRUEM-2470</td>\n",
       "      <td>0.74</td>\n",
       "      <td>33.21</td>\n",
       "      <td>TRUEM-2440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ensemble Refinement</td>\n",
       "      <td>ER MAD</td>\n",
       "      <td>FS+EG</td>\n",
       "      <td>reasoning=3, aggregation=1</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.54</td>\n",
       "      <td>25.50</td>\n",
       "      <td>TRUEM-2270</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.42</td>\n",
       "      <td>TRUEM-2468</td>\n",
       "      <td>0.76</td>\n",
       "      <td>10.64</td>\n",
       "      <td>TRUEM-2438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Ensemble Refinement</td>\n",
       "      <td>ER MAD</td>\n",
       "      <td>FS+EG</td>\n",
       "      <td>self consistency: reasoning=5</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.54</td>\n",
       "      <td>31.86</td>\n",
       "      <td>TRUEM-2263</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.53</td>\n",
       "      <td>TRUEM-2461</td>\n",
       "      <td>0.71</td>\n",
       "      <td>13.04</td>\n",
       "      <td>TRUEM-2432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ensemble Refinement</td>\n",
       "      <td>ER MAD</td>\n",
       "      <td>FS+EG</td>\n",
       "      <td>self consistency: reasoning=5</td>\n",
       "      <td>PaLM</td>\n",
       "      <td>0.47</td>\n",
       "      <td>9.57</td>\n",
       "      <td>TRUEM-2262</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.15</td>\n",
       "      <td>TRUEM-2460</td>\n",
       "      <td>0.71</td>\n",
       "      <td>4.30</td>\n",
       "      <td>TRUEM-2431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ensemble Refinement</td>\n",
       "      <td>ER MAD CoT</td>\n",
       "      <td>CoT</td>\n",
       "      <td>reasoning=3, aggregation=1</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.54</td>\n",
       "      <td>19.53</td>\n",
       "      <td>TRUEM-2265</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.44</td>\n",
       "      <td>TRUEM-2463</td>\n",
       "      <td>0.77</td>\n",
       "      <td>7.54</td>\n",
       "      <td>TRUEM-2433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ensemble Refinement</td>\n",
       "      <td>ER MAD CoT</td>\n",
       "      <td>CoT</td>\n",
       "      <td>self consistency: reasoning=5</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.54</td>\n",
       "      <td>22.28</td>\n",
       "      <td>TRUEM-2257</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.53</td>\n",
       "      <td>TRUEM-2455</td>\n",
       "      <td>0.78</td>\n",
       "      <td>8.75</td>\n",
       "      <td>TRUEM-2425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ensemble Refinement</td>\n",
       "      <td>ER MAD CoT</td>\n",
       "      <td>CoT</td>\n",
       "      <td>reasoning=3, aggregation=9</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.55</td>\n",
       "      <td>69.00</td>\n",
       "      <td>TRUEM-2538</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.50</td>\n",
       "      <td>TRUEM-2465</td>\n",
       "      <td>0.75</td>\n",
       "      <td>25.60</td>\n",
       "      <td>TRUEM-2435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ensemble Refinement</td>\n",
       "      <td>ER MAD CoT</td>\n",
       "      <td>CoT</td>\n",
       "      <td>self consistency: reasoning=5</td>\n",
       "      <td>PaLM</td>\n",
       "      <td>0.17</td>\n",
       "      <td>6.36</td>\n",
       "      <td>TRUEM-2256</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.15</td>\n",
       "      <td>TRUEM-2454</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2.50</td>\n",
       "      <td>TRUEM-2424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Ensemble Refinement</td>\n",
       "      <td>ER MAD CoT</td>\n",
       "      <td>FS-CoT</td>\n",
       "      <td>self consistency: reasoning=5</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.59</td>\n",
       "      <td>31.84</td>\n",
       "      <td>TRUEM-2259</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.75</td>\n",
       "      <td>TRUEM-2457</td>\n",
       "      <td>0.79</td>\n",
       "      <td>13.01</td>\n",
       "      <td>TRUEM-2427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Ensemble Refinement</td>\n",
       "      <td>ER MAD CoT</td>\n",
       "      <td>FS-CoT</td>\n",
       "      <td>reasoning=3, aggregation=9</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.60</td>\n",
       "      <td>83.03</td>\n",
       "      <td>TRUEM-2268</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.92</td>\n",
       "      <td>TRUEM-2466</td>\n",
       "      <td>0.78</td>\n",
       "      <td>37.22</td>\n",
       "      <td>TRUEM-2436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Ensemble Refinement</td>\n",
       "      <td>ER MAD CoT</td>\n",
       "      <td>FS-CoT</td>\n",
       "      <td>reasoning=3, aggregation=1</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.60</td>\n",
       "      <td>26.18</td>\n",
       "      <td>TRUEM-2266</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.61</td>\n",
       "      <td>TRUEM-2464</td>\n",
       "      <td>0.77</td>\n",
       "      <td>11.07</td>\n",
       "      <td>TRUEM-2434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ensemble Refinement</td>\n",
       "      <td>ER MAD CoT</td>\n",
       "      <td>FS-CoT</td>\n",
       "      <td>self consistency: reasoning=5</td>\n",
       "      <td>PaLM</td>\n",
       "      <td>0.52</td>\n",
       "      <td>9.56</td>\n",
       "      <td>TRUEM-2258</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.23</td>\n",
       "      <td>TRUEM-2456</td>\n",
       "      <td>0.72</td>\n",
       "      <td>4.29</td>\n",
       "      <td>TRUEM-2426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Multi-Persona</td>\n",
       "      <td>MP MAD</td>\n",
       "      <td>ANGEL+DEVIL</td>\n",
       "      <td>2 rounds max</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.49</td>\n",
       "      <td>14.27</td>\n",
       "      <td>TRUEM-2320</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.33</td>\n",
       "      <td>TRUEM-2489</td>\n",
       "      <td>0.57</td>\n",
       "      <td>7.15</td>\n",
       "      <td>TRUEM-2402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Multi-Persona</td>\n",
       "      <td>MP MAD</td>\n",
       "      <td>ANGEL+DEVIL</td>\n",
       "      <td>4 rounds max</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>14.70</td>\n",
       "      <td>TRUEM-2319</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.33</td>\n",
       "      <td>TRUEM-2491</td>\n",
       "      <td>0.60</td>\n",
       "      <td>9.52</td>\n",
       "      <td>TRUEM-2404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Multi-Persona</td>\n",
       "      <td>MP MAD</td>\n",
       "      <td>ANGEL+DEVIL</td>\n",
       "      <td>3 rounds max</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.51</td>\n",
       "      <td>14.60</td>\n",
       "      <td>TRUEM-2318</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.34</td>\n",
       "      <td>TRUEM-2490</td>\n",
       "      <td>0.59</td>\n",
       "      <td>8.49</td>\n",
       "      <td>TRUEM-2403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Society of Mind</td>\n",
       "      <td>SoM MAD</td>\n",
       "      <td>CoT</td>\n",
       "      <td>2 agents, 2 rounds, summarized answers</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.57</td>\n",
       "      <td>17.83</td>\n",
       "      <td>TRUEM-2273</td>\n",
       "      <td>0.69</td>\n",
       "      <td>15.26</td>\n",
       "      <td>TRUEM-2311</td>\n",
       "      <td>0.73</td>\n",
       "      <td>7.00</td>\n",
       "      <td>TRUEM-2390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Society of Mind</td>\n",
       "      <td>SoM MAD</td>\n",
       "      <td>CoT</td>\n",
       "      <td>2 agents, 2 rounds</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.58</td>\n",
       "      <td>18.05</td>\n",
       "      <td>TRUEM-2291</td>\n",
       "      <td>0.67</td>\n",
       "      <td>15.26</td>\n",
       "      <td>TRUEM-2325</td>\n",
       "      <td>0.76</td>\n",
       "      <td>7.00</td>\n",
       "      <td>TRUEM-2396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Society of Mind</td>\n",
       "      <td>SoM MAD</td>\n",
       "      <td>CoT</td>\n",
       "      <td>3 agents, 3 rounds</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.59</td>\n",
       "      <td>41.94</td>\n",
       "      <td>TRUEM-2411</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.95</td>\n",
       "      <td>TRUEM-2486</td>\n",
       "      <td>0.76</td>\n",
       "      <td>15.80</td>\n",
       "      <td>TRUEM-2399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Society of Mind</td>\n",
       "      <td>SoM MAD</td>\n",
       "      <td>CoT</td>\n",
       "      <td>2 agents, 3 rounds</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.59</td>\n",
       "      <td>26.94</td>\n",
       "      <td>TRUEM-2292</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.63</td>\n",
       "      <td>TRUEM-2484</td>\n",
       "      <td>0.76</td>\n",
       "      <td>10.50</td>\n",
       "      <td>TRUEM-2397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Society of Mind</td>\n",
       "      <td>SoM MAD</td>\n",
       "      <td>CoT</td>\n",
       "      <td>4 agents, 2 rounds, summarized answers</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.59</td>\n",
       "      <td>35.65</td>\n",
       "      <td>TRUEM-2287</td>\n",
       "      <td>0.71</td>\n",
       "      <td>30.52</td>\n",
       "      <td>TRUEM-2323</td>\n",
       "      <td>0.77</td>\n",
       "      <td>14.00</td>\n",
       "      <td>TRUEM-2394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Society of Mind</td>\n",
       "      <td>SoM MAD</td>\n",
       "      <td>CoT</td>\n",
       "      <td>3 agents, 2 rounds, summarized answers</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.59</td>\n",
       "      <td>26.74</td>\n",
       "      <td>TRUEM-2284</td>\n",
       "      <td>0.70</td>\n",
       "      <td>22.89</td>\n",
       "      <td>TRUEM-2321</td>\n",
       "      <td>0.76</td>\n",
       "      <td>10.50</td>\n",
       "      <td>TRUEM-2392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Society of Mind</td>\n",
       "      <td>SoM MAD</td>\n",
       "      <td>CoT</td>\n",
       "      <td>4 agents, 2 rounds</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.60</td>\n",
       "      <td>38.96</td>\n",
       "      <td>TRUEM-2413</td>\n",
       "      <td>0.70</td>\n",
       "      <td>30.81</td>\n",
       "      <td>TRUEM-2351</td>\n",
       "      <td>0.74</td>\n",
       "      <td>14.02</td>\n",
       "      <td>TRUEM-2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Society of Mind</td>\n",
       "      <td>SoM MAD</td>\n",
       "      <td>CoT</td>\n",
       "      <td>2 agents, 3 rounds, summarized answers</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.60</td>\n",
       "      <td>26.74</td>\n",
       "      <td>TRUEM-2282</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.63</td>\n",
       "      <td>TRUEM-2472</td>\n",
       "      <td>0.74</td>\n",
       "      <td>10.51</td>\n",
       "      <td>TRUEM-2391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Society of Mind</td>\n",
       "      <td>SoM MAD</td>\n",
       "      <td>CoT</td>\n",
       "      <td>4 agents, 3 rounds</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.61</td>\n",
       "      <td>58.52</td>\n",
       "      <td>TRUEM-2412</td>\n",
       "      <td>0.70</td>\n",
       "      <td>46.32</td>\n",
       "      <td>TRUEM-2356</td>\n",
       "      <td>0.74</td>\n",
       "      <td>21.40</td>\n",
       "      <td>TRUEM-2401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Society of Mind</td>\n",
       "      <td>SoM MAD</td>\n",
       "      <td>CoT</td>\n",
       "      <td>3 agents, 2 rounds</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.61</td>\n",
       "      <td>28.04</td>\n",
       "      <td>TRUEM-2293</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.63</td>\n",
       "      <td>TRUEM-2485</td>\n",
       "      <td>0.75</td>\n",
       "      <td>10.50</td>\n",
       "      <td>TRUEM-2398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Society of Mind</td>\n",
       "      <td>SoM MAD</td>\n",
       "      <td>CoT</td>\n",
       "      <td>4 agents, 3 rounds, summarized answers</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.61</td>\n",
       "      <td>53.48</td>\n",
       "      <td>TRUEM-2290</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.26</td>\n",
       "      <td>TRUEM-2482</td>\n",
       "      <td>0.72</td>\n",
       "      <td>21.01</td>\n",
       "      <td>TRUEM-2395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Society of Mind</td>\n",
       "      <td>SoM MAD</td>\n",
       "      <td>CoT</td>\n",
       "      <td>3 agents, 3 rounds, summarized answers</td>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.61</td>\n",
       "      <td>40.11</td>\n",
       "      <td>TRUEM-2286</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.94</td>\n",
       "      <td>TRUEM-2480</td>\n",
       "      <td>0.72</td>\n",
       "      <td>15.75</td>\n",
       "      <td>TRUEM-2393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            System Name Debate Prompt Agent Prompt  \\\n",
       "25         Single Agent             -          CoT   \n",
       "27         Single Agent             -          CoT   \n",
       "26         Single Agent             -          CoT   \n",
       "28         Single Agent             -          CoT   \n",
       "31         Single Agent             -           FS   \n",
       "32         Single Agent             -           FS   \n",
       "33         Single Agent             -        FS+EG   \n",
       "34         Single Agent             -        FS+EG   \n",
       "29         Single Agent             -       FS-CoT   \n",
       "30         Single Agent             -       FS-CoT   \n",
       "35         Single Agent             -       SIMPLE   \n",
       "36         Single Agent             -       SIMPLE   \n",
       "37         Single Agent             -          SPP   \n",
       "0              ChatEval        CE MAD          CoT   \n",
       "1              ChatEval        CE MAD          CoT   \n",
       "2              ChatEval        CE MAD          CoT   \n",
       "3              ChatEval        CE MAD          CoT   \n",
       "4              ChatEval        CE MAD          CoT   \n",
       "5              ChatEval        CE MAD          CoT   \n",
       "6   Ensemble Refinement        ER MAD           FS   \n",
       "7   Ensemble Refinement        ER MAD           FS   \n",
       "8   Ensemble Refinement        ER MAD           FS   \n",
       "9   Ensemble Refinement        ER MAD           FS   \n",
       "10  Ensemble Refinement        ER MAD        FS+EG   \n",
       "11  Ensemble Refinement        ER MAD        FS+EG   \n",
       "12  Ensemble Refinement        ER MAD        FS+EG   \n",
       "13  Ensemble Refinement        ER MAD        FS+EG   \n",
       "14  Ensemble Refinement    ER MAD CoT          CoT   \n",
       "15  Ensemble Refinement    ER MAD CoT          CoT   \n",
       "16  Ensemble Refinement    ER MAD CoT          CoT   \n",
       "17  Ensemble Refinement    ER MAD CoT          CoT   \n",
       "18  Ensemble Refinement    ER MAD CoT       FS-CoT   \n",
       "19  Ensemble Refinement    ER MAD CoT       FS-CoT   \n",
       "20  Ensemble Refinement    ER MAD CoT       FS-CoT   \n",
       "21  Ensemble Refinement    ER MAD CoT       FS-CoT   \n",
       "22        Multi-Persona        MP MAD  ANGEL+DEVIL   \n",
       "23        Multi-Persona        MP MAD  ANGEL+DEVIL   \n",
       "24        Multi-Persona        MP MAD  ANGEL+DEVIL   \n",
       "38      Society of Mind       SoM MAD          CoT   \n",
       "39      Society of Mind       SoM MAD          CoT   \n",
       "40      Society of Mind       SoM MAD          CoT   \n",
       "41      Society of Mind       SoM MAD          CoT   \n",
       "42      Society of Mind       SoM MAD          CoT   \n",
       "43      Society of Mind       SoM MAD          CoT   \n",
       "44      Society of Mind       SoM MAD          CoT   \n",
       "45      Society of Mind       SoM MAD          CoT   \n",
       "46      Society of Mind       SoM MAD          CoT   \n",
       "47      Society of Mind       SoM MAD          CoT   \n",
       "48      Society of Mind       SoM MAD          CoT   \n",
       "49      Society of Mind       SoM MAD          CoT   \n",
       "\n",
       "                                         Config  Agents  Score (MEDQA)  \\\n",
       "25                                               GPT3.5           0.51   \n",
       "27                                               GPT3.5           0.49   \n",
       "26                                                 PaLM           0.14   \n",
       "28                                                 PaLM           0.17   \n",
       "31                                               GPT3.5           0.53   \n",
       "32                                                 PaLM           0.46   \n",
       "33                                               GPT3.5           0.54   \n",
       "34                                                 PaLM           0.47   \n",
       "29                                               GPT3.5           0.56   \n",
       "30                                                 PaLM           0.49   \n",
       "35                                               GPT3.5           0.52   \n",
       "36                                                 PaLM           0.46   \n",
       "37                                  SPP Synergy  GPT3.5           0.53   \n",
       "0                          3 rounds, one by one  GPT3.5           0.53   \n",
       "1                   2 rounds, simultaneous talk  GPT3.5           0.54   \n",
       "2   3 rounds, simultaneous talk with summarizer  GPT3.5           0.55   \n",
       "3                          2 rounds, one by one  GPT3.5           0.55   \n",
       "4   2 rounds, simultaneous talk with summarizer  GPT3.5           0.55   \n",
       "5                   3 rounds, simultaneous talk  GPT3.5           0.57   \n",
       "6                    reasoning=3, aggregation=9  GPT3.5           0.53   \n",
       "7                    reasoning=3, aggregation=1  GPT3.5           0.53   \n",
       "8                 self consistency: reasoning=5  GPT3.5           0.53   \n",
       "9                 self consistency: reasoning=5    PaLM           0.46   \n",
       "10                   reasoning=3, aggregation=9  GPT3.5           0.54   \n",
       "11                   reasoning=3, aggregation=1  GPT3.5           0.54   \n",
       "12                self consistency: reasoning=5  GPT3.5           0.54   \n",
       "13                self consistency: reasoning=5    PaLM           0.47   \n",
       "14                   reasoning=3, aggregation=1  GPT3.5           0.54   \n",
       "15                self consistency: reasoning=5  GPT3.5           0.54   \n",
       "16                   reasoning=3, aggregation=9  GPT3.5           0.55   \n",
       "17                self consistency: reasoning=5    PaLM           0.17   \n",
       "18                self consistency: reasoning=5  GPT3.5           0.59   \n",
       "19                   reasoning=3, aggregation=9  GPT3.5           0.60   \n",
       "20                   reasoning=3, aggregation=1  GPT3.5           0.60   \n",
       "21                self consistency: reasoning=5    PaLM           0.52   \n",
       "22                                 2 rounds max  GPT3.5           0.49   \n",
       "23                                 4 rounds max  GPT3.5           0.50   \n",
       "24                                 3 rounds max  GPT3.5           0.51   \n",
       "38       2 agents, 2 rounds, summarized answers  GPT3.5           0.57   \n",
       "39                           2 agents, 2 rounds  GPT3.5           0.58   \n",
       "40                           3 agents, 3 rounds  GPT3.5           0.59   \n",
       "41                           2 agents, 3 rounds  GPT3.5           0.59   \n",
       "42       4 agents, 2 rounds, summarized answers  GPT3.5           0.59   \n",
       "43       3 agents, 2 rounds, summarized answers  GPT3.5           0.59   \n",
       "44                           4 agents, 2 rounds  GPT3.5           0.60   \n",
       "45       2 agents, 3 rounds, summarized answers  GPT3.5           0.60   \n",
       "46                           4 agents, 3 rounds  GPT3.5           0.61   \n",
       "47                           3 agents, 2 rounds  GPT3.5           0.61   \n",
       "48       4 agents, 3 rounds, summarized answers  GPT3.5           0.61   \n",
       "49       3 agents, 3 rounds, summarized answers  GPT3.5           0.61   \n",
       "\n",
       "    Cost \\$ (MEDQA)  ID (MEDQA)  Score (MMLU)  Cost \\$ (MMLU)   ID (MMLU)  \\\n",
       "25             4.46  TRUEM-2245          0.65            3.82  TRUEM-2307   \n",
       "27             4.46  TRUEM-2249          0.67            0.11  TRUEM-2447   \n",
       "26             1.28  TRUEM-2248          0.30            0.03  TRUEM-2445   \n",
       "28             1.27  TRUEM-2247          0.33            0.03  TRUEM-2442   \n",
       "31             4.46  TRUEM-2253          0.70            0.11  TRUEM-2451   \n",
       "32             1.27  TRUEM-2252          0.50            0.03  TRUEM-2450   \n",
       "33             6.37  TRUEM-2255          0.80            0.11  TRUEM-2453   \n",
       "34             1.91  TRUEM-2254          0.70            0.03  TRUEM-2452   \n",
       "29             6.37  TRUEM-2251          0.70            0.15  TRUEM-2449   \n",
       "30             1.91  TRUEM-2250          0.63            0.04  TRUEM-2448   \n",
       "35             4.46  TRUEM-2415          0.73            0.11  TRUEM-2443   \n",
       "36             1.27  TRUEM-2279          0.68            1.09  TRUEM-2308   \n",
       "37             6.38  TRUEM-2264          0.70            0.04  TRUEM-2501   \n",
       "0             34.81  TRUEM-2441          0.70            0.73  TRUEM-2493   \n",
       "1             19.90  TRUEM-2302          0.73            0.43  TRUEM-2494   \n",
       "2             36.78  TRUEM-2429          0.73            0.84  TRUEM-2497   \n",
       "3             20.55  TRUEM-2414          0.69           16.28  TRUEM-2362   \n",
       "4             22.58  TRUEM-2304          0.70            0.53  TRUEM-2496   \n",
       "5             33.26  TRUEM-2303          0.83            0.72  TRUEM-2495   \n",
       "6             53.57  TRUEM-2271          0.63            1.26  TRUEM-2469   \n",
       "7             17.83  TRUEM-2269          0.67            0.42  TRUEM-2467   \n",
       "8             22.28  TRUEM-2261          0.70            0.53  TRUEM-2459   \n",
       "9              6.36  TRUEM-2260          0.50            0.15  TRUEM-2458   \n",
       "10            76.60  TRUEM-2272          0.83            1.26  TRUEM-2470   \n",
       "11            25.50  TRUEM-2270          0.83            0.42  TRUEM-2468   \n",
       "12            31.86  TRUEM-2263          0.73            0.53  TRUEM-2461   \n",
       "13             9.57  TRUEM-2262          0.63            0.15  TRUEM-2460   \n",
       "14            19.53  TRUEM-2265          0.70            0.44  TRUEM-2463   \n",
       "15            22.28  TRUEM-2257          0.70            0.53  TRUEM-2455   \n",
       "16            69.00  TRUEM-2538          0.67            1.50  TRUEM-2465   \n",
       "17             6.36  TRUEM-2256          0.33            0.15  TRUEM-2454   \n",
       "18            31.84  TRUEM-2259          0.70            0.75  TRUEM-2457   \n",
       "19            83.03  TRUEM-2268          0.73            1.92  TRUEM-2466   \n",
       "20            26.18  TRUEM-2266          0.77            0.61  TRUEM-2464   \n",
       "21             9.56  TRUEM-2258          0.63            0.23  TRUEM-2456   \n",
       "22            14.27  TRUEM-2320          0.63            0.33  TRUEM-2489   \n",
       "23            14.70  TRUEM-2319          0.67            0.33  TRUEM-2491   \n",
       "24            14.60  TRUEM-2318          0.63            0.34  TRUEM-2490   \n",
       "38            17.83  TRUEM-2273          0.69           15.26  TRUEM-2311   \n",
       "39            18.05  TRUEM-2291          0.67           15.26  TRUEM-2325   \n",
       "40            41.94  TRUEM-2411          0.63            0.95  TRUEM-2486   \n",
       "41            26.94  TRUEM-2292          0.73            0.63  TRUEM-2484   \n",
       "42            35.65  TRUEM-2287          0.71           30.52  TRUEM-2323   \n",
       "43            26.74  TRUEM-2284          0.70           22.89  TRUEM-2321   \n",
       "44            38.96  TRUEM-2413          0.70           30.81  TRUEM-2351   \n",
       "45            26.74  TRUEM-2282          0.73            0.63  TRUEM-2472   \n",
       "46            58.52  TRUEM-2412          0.70           46.32  TRUEM-2356   \n",
       "47            28.04  TRUEM-2293          0.73            0.63  TRUEM-2485   \n",
       "48            53.48  TRUEM-2290          0.77            1.26  TRUEM-2482   \n",
       "49            40.11  TRUEM-2286          0.67            0.94  TRUEM-2480   \n",
       "\n",
       "    Score (PUBMEDQA)  Cost \\$ (PUBMEDQA) ID (PUBMEDQA)  \n",
       "25              0.77                1.75    TRUEM-2389  \n",
       "27              0.74                1.75    TRUEM-2479  \n",
       "26              0.42                0.50    TRUEM-2388  \n",
       "28              0.38                0.50    TRUEM-2505  \n",
       "31              0.71                1.75    TRUEM-2421  \n",
       "32              0.75                0.50    TRUEM-2419  \n",
       "33              0.70                2.61    TRUEM-2423  \n",
       "34              0.65                0.86    TRUEM-2422  \n",
       "29              0.79                2.60    TRUEM-2417  \n",
       "30              0.71                0.86    TRUEM-2513  \n",
       "35              0.71                1.75    TRUEM-2387  \n",
       "36              0.76                0.50    TRUEM-2386  \n",
       "37              0.69                2.55    TRUEM-2385  \n",
       "0               0.76               12.60    TRUEM-2406  \n",
       "1               0.74                7.27    TRUEM-2407  \n",
       "2               0.77               14.01    TRUEM-2410  \n",
       "3               0.76                7.64    TRUEM-2405  \n",
       "4               0.72                8.76    TRUEM-2409  \n",
       "5               0.77               12.14    TRUEM-2408  \n",
       "6               0.72               21.00    TRUEM-2439  \n",
       "7               0.72                7.00    TRUEM-2437  \n",
       "8               0.70                8.75    TRUEM-2430  \n",
       "9               0.76                2.50    TRUEM-2428  \n",
       "10              0.74               33.21    TRUEM-2440  \n",
       "11              0.76               10.64    TRUEM-2438  \n",
       "12              0.71               13.04    TRUEM-2432  \n",
       "13              0.71                4.30    TRUEM-2431  \n",
       "14              0.77                7.54    TRUEM-2433  \n",
       "15              0.78                8.75    TRUEM-2425  \n",
       "16              0.75               25.60    TRUEM-2435  \n",
       "17              0.38                2.50    TRUEM-2424  \n",
       "18              0.79               13.01    TRUEM-2427  \n",
       "19              0.78               37.22    TRUEM-2436  \n",
       "20              0.77               11.07    TRUEM-2434  \n",
       "21              0.72                4.29    TRUEM-2426  \n",
       "22              0.57                7.15    TRUEM-2402  \n",
       "23              0.60                9.52    TRUEM-2404  \n",
       "24              0.59                8.49    TRUEM-2403  \n",
       "38              0.73                7.00    TRUEM-2390  \n",
       "39              0.76                7.00    TRUEM-2396  \n",
       "40              0.76               15.80    TRUEM-2399  \n",
       "41              0.76               10.50    TRUEM-2397  \n",
       "42              0.77               14.00    TRUEM-2394  \n",
       "43              0.76               10.50    TRUEM-2392  \n",
       "44              0.74               14.02    TRUEM-2400  \n",
       "45              0.74               10.51    TRUEM-2391  \n",
       "46              0.74               21.40    TRUEM-2401  \n",
       "47              0.75               10.50    TRUEM-2398  \n",
       "48              0.72               21.01    TRUEM-2395  \n",
       "49              0.72               15.75    TRUEM-2393  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df[\"Debate Config\"] = \n",
    "df[\"Config\"] = df[\"Config\"].str.replace(\", GPT\",\"\")\\\n",
    "            .str.replace(\"GPT\",\"\")\\\n",
    "            .str.replace(\", PaLM\",\"\")\\\n",
    "            .str.replace(\"PaLM\",\"\")\\\n",
    "            .str.replace(\" - ER\",\"\")\\\n",
    "            .str.replace(\"1:0 - single agent\", \"\")\\\n",
    "            .str.replace(\"1:0 - single_agent\", \"\")\\\n",
    "            .str.replace(\"5:0 - self_consistency\", \"self consistency: reasoning=5\")\\\n",
    "            .str.replace(\"3:1\", \"reasoning=3, aggregation=1\")\\\n",
    "            .str.replace(\"3:9\", \"reasoning=3, aggregation=9\")\\\n",
    "            .str.replace(\"_\", \" \")\n",
    "df.sort_values(by=[\"Debate Prompt\", \"Agent Prompt\", \"Agents\"], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffee630b-9c18-4a61-a0ed-02e1b7fc7a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['System Name', 'Debate Prompt', 'Agent Prompt', 'Config', 'Agents', 'Score (MEDQA)', 'Cost \\$ (MEDQA)', 'Score (MMLU)', 'Cost \\$ (MMLU)', 'Score (PUBMEDQA)', 'Cost \\$ (PUBMEDQA)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8267f533-3e67-475d-a31a-e2b5e65024a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{longtable}{lllllrrlr}\n",
      "\\toprule\n",
      "System Name & Debate Prompt & Agent Prompt & Config & Agents & Score (PUBMEDQA) & Cost \\$ (PUBMEDQA) & ID (PUBMEDQA) & IP (PUBMEDQA) \\\\\n",
      "\\midrule\n",
      "\\endfirsthead\n",
      "\\toprule\n",
      "System Name & Debate Prompt & Agent Prompt & Config & Agents & Score (PUBMEDQA) & Cost \\$ (PUBMEDQA) & ID (PUBMEDQA) & IP (PUBMEDQA) \\\\\n",
      "\\midrule\n",
      "\\endhead\n",
      "\\midrule\n",
      "\\multicolumn{9}{r}{Continued on next page} \\\\\n",
      "\\midrule\n",
      "\\endfoot\n",
      "\\bottomrule\n",
      "\\endlastfoot\n",
      "ChatEval & chateval_ma_debate & cot & 2 rounds, simultaneous_talk_with_summarizer & GPT3.5 & 0.72 & 8.76 & TRUEM-2409 & 0.00 \\\\\n",
      "ChatEval & chateval_ma_debate & cot & 2 rounds, simultaneous_talk & GPT3.5 & 0.74 & 7.27 & TRUEM-2407 & 0.00 \\\\\n",
      "ChatEval & chateval_ma_debate & cot & 3 rounds, one_by_one & GPT3.5 & 0.76 & 12.60 & TRUEM-2406 & 0.00 \\\\\n",
      "ChatEval & chateval_ma_debate & cot & 2 rounds, one_by_one & GPT3.5 & 0.76 & 7.64 & TRUEM-2405 & 0.00 \\\\\n",
      "ChatEval & chateval_ma_debate & cot & 3 rounds, simultaneous_talk_with_summarizer & GPT3.5 & 0.77 & 14.01 & TRUEM-2410 & 0.00 \\\\\n",
      "ChatEval & chateval_ma_debate & cot & 3 rounds, simultaneous_talk & GPT3.5 & 0.77 & 12.14 & TRUEM-2408 & 0.00 \\\\\n",
      "Ensemble Refinement & er_debate & er_few_shot & 5:0 - self_consistency, GPT & GPT3.5 & 0.70 & 8.75 & TRUEM-2430 & 0.00 \\\\\n",
      "Ensemble Refinement & er_debate & er_few_shot & 3:9 - ER, GPT & GPT3.5 & 0.72 & 21.00 & TRUEM-2439 & 0.00 \\\\\n",
      "Ensemble Refinement & er_debate & er_few_shot & 3:1 - ER, GPT & GPT3.5 & 0.72 & 7.00 & TRUEM-2437 & 0.00 \\\\\n",
      "Ensemble Refinement & er_debate & er_few_shot & 5:0 - self_consistency, PaLM & PaLM & 0.76 & 2.50 & TRUEM-2428 & 0.00 \\\\\n",
      "Ensemble Refinement & er_debate & er_few_shot + FS & 5:0 - self_consistency, GPT & GPT3.5 & 0.71 & 13.04 & TRUEM-2432 & 0.00 \\\\\n",
      "Ensemble Refinement & er_debate & er_few_shot + FS & 3:9 - ER, GPT & GPT3.5 & 0.74 & 33.21 & TRUEM-2440 & 0.00 \\\\\n",
      "Ensemble Refinement & er_debate & er_few_shot + FS & 3:1 - ER, GPT & GPT3.5 & 0.76 & 10.64 & TRUEM-2438 & 0.00 \\\\\n",
      "Ensemble Refinement & er_debate & er_few_shot + FS & 5:0 - self_consistency, PaLM & PaLM & 0.71 & 4.30 & TRUEM-2431 & 0.08 \\\\\n",
      "Ensemble Refinement & er_debate_cot & er_cot & 3:9 - ER, GPT & GPT3.5 & 0.75 & 25.60 & TRUEM-2435 & 0.08 \\\\\n",
      "Ensemble Refinement & er_debate_cot & er_cot & 3:1 - ER, GPT & GPT3.5 & 0.77 & 7.54 & TRUEM-2433 & 0.09 \\\\\n",
      "Ensemble Refinement & er_debate_cot & er_cot & 5:0 - self_consistency, GPT & GPT3.5 & 0.78 & 8.75 & TRUEM-2425 & 0.15 \\\\\n",
      "Ensemble Refinement & er_debate_cot & er_cot & 5:0 - self_consistency, PaLM & PaLM & 0.38 & 2.50 & TRUEM-2424 & 0.72 \\\\\n",
      "Ensemble Refinement & er_debate_cot & er_cot + FS & 3:1 - ER, GPT & GPT3.5 & 0.77 & 11.07 & TRUEM-2434 & 0.00 \\\\\n",
      "Ensemble Refinement & er_debate_cot & er_cot + FS & 3:9 - ER, GPT & GPT3.5 & 0.78 & 37.22 & TRUEM-2436 & 0.00 \\\\\n",
      "Ensemble Refinement & er_debate_cot & er_cot + FS & 5:0 - self_consistency, GPT & GPT3.5 & 0.79 & 13.01 & TRUEM-2427 & 0.00 \\\\\n",
      "Ensemble Refinement & er_debate_cot & er_cot + FS & 5:0 - self_consistency, PaLM & PaLM & 0.72 & 4.29 & TRUEM-2426 & 0.09 \\\\\n",
      "Multi-Persona & tsinghua_ma_debate & angel & 2 rounds max & GPT3.5 & 0.57 & 7.15 & TRUEM-2402 & NaN \\\\\n",
      "Multi-Persona & tsinghua_ma_debate & angel & 3 rounds max & GPT3.5 & 0.59 & 8.49 & TRUEM-2403 & NaN \\\\\n",
      "Multi-Persona & tsinghua_ma_debate & angel & 4 rounds max & GPT3.5 & 0.60 & 9.52 & TRUEM-2404 & NaN \\\\\n",
      "Single Agent & - & cot & GPT & GPT3.5 & 0.77 & 1.75 & TRUEM-2389 & 0.00 \\\\\n",
      "Single Agent & - & cot & PaLM & PaLM & 0.42 & 0.50 & TRUEM-2388 & 0.32 \\\\\n",
      "Single Agent & - & er_cot & 1:0 - single_agent, GPT & GPT3.5 & 0.73 & 1.75 & TRUEM-2420 & 0.04 \\\\\n",
      "Single Agent & - & er_cot & 1:0 - single_agent, GPT & GPT3.5 & 0.74 & 1.75 & TRUEM-2479 & 0.04 \\\\\n",
      "Single Agent & - & er_cot & 1:0 - single_agent, PaLM & PaLM & 0.38 & 0.50 & TRUEM-2505 & 0.43 \\\\\n",
      "Single Agent & - & er_cot + FS & 1:0 - single_agent, GPT & GPT3.5 & 0.79 & 2.60 & TRUEM-2477 & 0.00 \\\\\n",
      "Single Agent & - & er_cot + FS & 1:0 - single_agent, GPT & GPT3.5 & 0.79 & 2.60 & TRUEM-2417 & 0.00 \\\\\n",
      "Single Agent & - & er_cot + FS & 1:0 - single_agent, PaLM & PaLM & 0.71 & 0.86 & TRUEM-2513 & 0.03 \\\\\n",
      "Single Agent & - & er_few_shot & 1:0 - single_agent, GPT & GPT3.5 & 0.71 & 1.75 & TRUEM-2421 & 0.00 \\\\\n",
      "Single Agent & - & er_few_shot & 1:0 - single_agent, PaLM & PaLM & 0.75 & 0.50 & TRUEM-2419 & 0.00 \\\\\n",
      "Single Agent & - & er_few_shot + FS & 1:0 - single_agent, GPT & GPT3.5 & 0.70 & 2.61 & TRUEM-2423 & 0.00 \\\\\n",
      "Single Agent & - & er_few_shot + FS & 1:0 - single_agent, PaLM & PaLM & 0.65 & 0.86 & TRUEM-2422 & 0.04 \\\\\n",
      "Single Agent & - & simple & GPT & GPT3.5 & 0.71 & 1.75 & TRUEM-2387 & 0.00 \\\\\n",
      "Single Agent & - & simple & PaLM & PaLM & 0.76 & 0.50 & TRUEM-2386 & 0.00 \\\\\n",
      "Single Agent & - & spp_original & SPP Synergy & GPT3.5 & 0.69 & 2.55 & TRUEM-2385 & 0.00 \\\\\n",
      "Society of Mind & google_ma_debate & cot & 4 agents, 3 rounds, summarized answers & GPT3.5 & 0.72 & 21.01 & TRUEM-2395 & 0.00 \\\\\n",
      "Society of Mind & google_ma_debate & cot & 3 agents, 3 rounds, summarized answers & GPT3.5 & 0.72 & 15.75 & TRUEM-2393 & 0.00 \\\\\n",
      "Society of Mind & google_ma_debate & cot & 2 agents, 2 rounds, summarized answers & GPT3.5 & 0.73 & 7.00 & TRUEM-2390 & 0.00 \\\\\n",
      "Society of Mind & google_ma_debate & cot & 4 agents, 3 rounds & GPT3.5 & 0.74 & 21.40 & TRUEM-2401 & 0.01 \\\\\n",
      "Society of Mind & google_ma_debate & cot & 4 agents, 2 rounds & GPT3.5 & 0.74 & 14.02 & TRUEM-2400 & 0.00 \\\\\n",
      "Society of Mind & google_ma_debate & cot & 2 agents, 3 rounds, summarized answers & GPT3.5 & 0.74 & 10.51 & TRUEM-2391 & 0.00 \\\\\n",
      "Society of Mind & google_ma_debate & cot & 3 agents, 2 rounds & GPT3.5 & 0.75 & 10.50 & TRUEM-2398 & 0.00 \\\\\n",
      "Society of Mind & google_ma_debate & cot & 3 agents, 3 rounds & GPT3.5 & 0.76 & 15.80 & TRUEM-2399 & 0.00 \\\\\n",
      "Society of Mind & google_ma_debate & cot & 2 agents, 3 rounds & GPT3.5 & 0.76 & 10.50 & TRUEM-2397 & 0.00 \\\\\n",
      "Society of Mind & google_ma_debate & cot & 2 agents, 2 rounds & GPT3.5 & 0.76 & 7.00 & TRUEM-2396 & 0.00 \\\\\n",
      "Society of Mind & google_ma_debate & cot & 3 agents, 2 rounds, summarized answers & GPT3.5 & 0.76 & 10.50 & TRUEM-2392 & 0.00 \\\\\n",
      "Society of Mind & google_ma_debate & cot & 4 agents, 2 rounds, summarized answers & GPT3.5 & 0.77 & 14.00 & TRUEM-2394 & 0.00 \\\\\n",
      "\\end{longtable}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table = df.to_latex(float_format=\"{:0.2f}\".format, index=False, longtable=True, sparsify=True, multirow=True)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f319307f-3ef1-453a-92e6-6fef11c8377d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9631d454-f7d6-4fa1-b093-b43939db7007",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
